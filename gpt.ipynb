{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "191b5219-2af8-41a5-ac96-cd9f27601bb2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Preprocesing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5dcf6c3-3589-441f-8e7a-3461990fdb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', \"'\", ',', '-', '.', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "62\n"
     ]
    }
   ],
   "source": [
    "# https://www.youtube.com/watch?v=kCc8FmEb1nY&ab_channel=AndrejKarpathy\n",
    "import torch\n",
    "\n",
    "# Load dataset\n",
    "with open(\"shakespear.txt\") as fn:\n",
    "    text = fn.read()\n",
    "\n",
    "# Get unique lsit\n",
    "chars = sorted(list(set(text)))\n",
    "\n",
    "vocab_size = len(chars)\n",
    "print(chars)\n",
    "print(len(chars))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e732195c-bddc-43da-9dd0-f35ef9533ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43, 40, 47, 47, 50]\n",
      "['h', 'e', 'l', 'l', 'o']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize. Chars -> intergers/index\n",
    "s2i = {ch: i for i, ch in enumerate(chars)}\n",
    "i2s = {i: ch for i, ch in enumerate(chars)}\n",
    "encode = lambda x: [s2i[ch] for ch in x]\n",
    "decode = lambda x: [i2s[i] for i in x]\n",
    "\n",
    "print(encode(\"hello\"))\n",
    "print(decode(encode(\"hello\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e56715-0275-4fe1-b302-9933cd51e201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([99993])\n",
      "tensor([29, 43, 36, 55,  4,  1, 51, 50, 50, 53,  1, 38, 50, 49, 55, 40, 48, 51,\n",
      "        55,  4,  1, 50, 53,  1, 38, 47, 36, 44, 48,  3, 39,  1, 55, 43, 50, 56,\n",
      "         1, 54, 47, 40, 51, 55,  1, 54, 50,  1, 41, 36, 44, 55, 43, 41, 56, 47,\n",
      "         4,  0, 18,  1, 48, 36, 60,  1, 38, 50, 49, 55, 53, 44, 57, 40,  1, 50,\n",
      "        56, 53,  1, 41, 36, 55, 43, 40, 53,  8,  1, 36, 49, 39,  4,  1, 44, 49,\n",
      "         1, 55, 43, 40, 44, 53,  1, 39, 40, 41, 40, 36, 55, 40, 39,  1, 52, 56,\n",
      "        40, 40, 49,  4,  0, 17, 40, 53,  1, 41, 47, 40, 54, 43,  1, 37, 53, 50,\n",
      "        46, 40,  1, 48, 40,  1, 36, 49, 39,  1, 51, 56, 55, 55, 36, 49, 38, 40,\n",
      "         1, 50, 41,  1, 40, 59, 51, 40, 39, 44, 55, 44, 50, 49,  1, 43, 50, 56,\n",
      "        54, 40,  4,  0, 10, 49, 39,  1, 44, 49,  1, 55, 43, 36, 55,  1, 54, 36,\n",
      "        48, 40,  1, 55, 43, 36, 55,  1, 40, 57, 40, 53,  1, 18,  1, 47, 36, 48,\n",
      "        40, 49, 55,  1, 55, 43, 44, 54,  1, 54, 55, 50, 48, 36, 38, 43,  4,  0,\n",
      "        10, 49, 39,  1, 43, 40,  4,  1, 49, 50, 53,  1, 11, 56, 55, 47, 60,  1,\n",
      "        36, 49, 39,  1, 48, 60,  1, 41, 56, 53, 60,  4,  1, 46, 49, 50, 58, 44,\n",
      "        49, 42,  1, 40, 57, 40, 53, 60, 55, 43, 44, 49, 42,  0, 16, 53, 40, 58,\n",
      "         1, 39, 36, 44, 47, 60,  1, 40, 57, 40, 53,  4,  1, 43, 44, 54,  1, 42,\n",
      "        53, 40, 36, 55,  1, 54, 55, 53, 40, 49, 42, 55, 43,  1, 36, 49, 39,  1,\n",
      "        55, 43, 50, 56, 42, 43, 55,  0, 29, 43, 40,  1, 37, 53, 44, 42, 43, 55,\n",
      "         1, 37, 56, 39, 54,  1, 50, 41,  1, 48, 44, 49, 40,  1, 50, 58, 49,  6,\n",
      "         0,  0, 11, 18, 24, 23, 13, 14, 21, 21, 24,  7,  0, 22, 36, 53, 53, 60,\n",
      "         4,  1, 55, 43, 36, 55,  1, 44, 55,  1, 48, 36, 60,  1, 49, 50, 55,  1,\n",
      "        51, 53, 36, 60,  1, 55, 43, 40, 44, 53,  1, 51, 36, 55, 44, 40, 49, 38,\n",
      "        40,  6,  3,  0,  0, 20, 18, 23, 16,  1, 21, 14, 10, 27,  7,  0, 29, 43,\n",
      "        40,  1, 44, 49, 54, 55, 36, 49, 55,  1, 38, 50, 48, 48, 50, 49,  1, 48,\n",
      "        36, 44, 39,  4,  1, 36, 54,  1, 58, 40,  1, 48, 36, 60,  1, 47, 40, 54,\n",
      "        54,  1, 37, 40,  0, 36,  1, 37, 53, 36, 57, 40,  1, 42, 40, 49, 55, 47,\n",
      "        40, 48, 36, 49,  1, 36, 49, 39,  1, 45, 50, 44, 49, 40, 53,  7,  1, 43,\n",
      "        40,  1, 55, 43, 36, 55,  1, 41, 44, 49, 39, 54,  1, 56, 54,  1, 58, 44,\n",
      "        55, 43,  1, 58, 36, 59,  0, 10, 49, 39,  1, 50, 58, 40,  1, 54, 50,  1,\n",
      "        41, 56, 47, 47,  1, 50, 41,  1, 51, 53, 40, 54, 40, 49, 38, 40,  1, 36,\n",
      "        49, 39,  1, 50, 56, 53,  1, 41, 50, 50, 39, 40, 53,  1, 36, 55,  1, 50,\n",
      "        56, 53,  0, 54, 55, 36, 57, 40, 54,  6,  1, 18, 55,  1, 44, 54,  1, 53,\n",
      "        40, 48, 50, 53, 54, 40, 39,  1, 55, 43, 40,  1, 37, 53, 44, 39, 36, 47,\n",
      "         3, 54,  1, 48, 36, 49,  1, 43, 44, 54,  1, 42, 53, 36, 38, 40,  0, 41,\n",
      "        50, 53,  1, 40, 57, 40, 53, 60,  1, 37, 56, 54, 44, 49, 40, 54, 54,  1,\n",
      "        44, 49,  1, 48, 60,  1, 55, 50, 49, 42, 56, 40,  4,  1, 37, 56, 55,  1,\n",
      "        18,  1, 58, 36, 54,  1, 55, 43, 44, 49, 46, 44, 49, 42,  0, 55, 43, 36,\n",
      "        55,  1, 43, 40,  1, 38, 50, 49, 55, 40, 49, 39, 54,  4,  1, 43, 40,  1,\n",
      "        43, 36, 55, 43,  1, 53, 40, 54, 51, 40, 38, 55, 40, 39,  1, 55, 43, 40,\n",
      "        40,  6,  0,  0, 11, 18, 27, 24, 23,  7,  0, 28, 43, 40,  1, 47, 40, 41,\n",
      "        55,  1, 55, 43, 40, 40,  1, 50, 49,  4,  1, 18,  3, 47, 47,  1, 39, 44,\n",
      "        40,  1, 55, 50,  1, 37, 47, 40, 54, 54, 40, 39,  1, 36, 49, 39,  1, 48,\n",
      "        50, 54, 55,  1, 53, 40, 36, 54, 50, 49, 36, 37, 47, 40,  0, 23, 36, 55,\n",
      "        56, 53, 40,  1, 44, 49,  1, 55, 43, 44, 54,  1, 43, 50, 49, 50, 56, 53,\n",
      "         4,  1, 36, 49, 39,  1, 43, 40, 53,  1, 37, 50, 54, 50, 48,  1, 44, 54,\n",
      "         1, 54, 36, 41, 40,  4,  1, 54, 50, 48, 40,  0, 50, 55, 43, 40, 53, 54,\n",
      "         1, 41, 53, 50, 48,  1, 43, 44, 54,  1, 54, 51, 40, 40, 39, 60,  5, 37,\n",
      "        44, 53, 55, 43,  4,  1, 36,  1, 37, 44, 47, 47,  1, 36, 49, 39,  1, 36,\n",
      "        54,  0, 15, 50, 53, 40, 54, 55, 40, 48,  1, 58, 44, 55, 43,  1, 27, 44,\n",
      "        38, 43, 36, 53, 39,  1, 44, 49,  1, 60, 50, 56, 53,  1, 43, 40, 36, 53,\n",
      "        55,  0, 11, 40,  1, 52, 56, 40, 54, 55, 44, 50, 49,  3, 39,  1, 50, 49,\n",
      "         4,  1, 49, 50, 53,  1, 55, 43, 36, 55,  1, 18,  1, 58, 36, 54,  1, 40,\n",
      "        49, 50, 56, 42, 43,  7,  0, 32, 43, 44, 38, 43,  1, 50, 41,  1, 36,  1,\n",
      "        51, 36, 53, 55, 44, 40, 53,  1, 41, 50, 53, 55, 43,  1, 55, 43, 40,  1,\n",
      "        50, 37, 54, 40, 53, 54,  1, 39,  3, 51, 56, 49, 44, 54, 43,  3, 39,  1,\n",
      "        55, 43, 40,  1, 43, 36, 55, 40,  0, 29])\n"
     ]
    }
   ],
   "source": [
    "# Tokenize whole training set\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape)\n",
    "print(data[:1000])\n",
    "\n",
    "# Train/val\n",
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba882612-ed7f-4e72-a477-5e728a4642c7",
   "metadata": {},
   "source": [
    "How we grab an input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26b6a6f4-ce2b-4b88-8202-ba494b0617ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([29, 43, 36, 55,  4,  1, 51, 50, 50])\n"
     ]
    }
   ],
   "source": [
    "context_length = 8\n",
    "print(train_data[: context_length + 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aecd1af-f66a-412e-99ee-9a5907409322",
   "metadata": {},
   "source": [
    "Example of how it's auto regressive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54798b9e-5e9d-41bd-931c-c245cca9c116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using input tensor([29]) the target is : 43\n",
      "using input tensor([29, 43]) the target is : 36\n",
      "using input tensor([29, 43, 36]) the target is : 55\n",
      "using input tensor([29, 43, 36, 55]) the target is : 4\n",
      "using input tensor([29, 43, 36, 55,  4]) the target is : 1\n",
      "using input tensor([29, 43, 36, 55,  4,  1]) the target is : 51\n",
      "using input tensor([29, 43, 36, 55,  4,  1, 51]) the target is : 50\n",
      "using input tensor([29, 43, 36, 55,  4,  1, 51, 50]) the target is : 50\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:context_length]\n",
    "y = train_data[1:context_length+1]\n",
    "for t in range(context_length):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"using input {context} the target is : {target}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b43b36-389b-4bc7-ae3f-74d5e8f920b4",
   "metadata": {},
   "source": [
    "sample minibatch: notice input encodes autoregressive style inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25eb2f84-bfc1-4120-991a-876f500a2ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[36, 45, 40, 54, 55, 60,  6,  0],\n",
      "        [47, 47,  1, 42, 50,  4,  0, 10],\n",
      "        [18,  1, 54, 40, 40,  0, 15, 50],\n",
      "        [49, 50,  1, 51, 53, 50, 51, 43]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[45, 40, 54, 55, 60,  6,  0,  0],\n",
      "        [47,  1, 42, 50,  4,  0, 10, 49],\n",
      "        [ 1, 54, 40, 40,  0, 15, 50, 53],\n",
      "        [50,  1, 51, 53, 50, 51, 43, 40]])\n",
      "----\n",
      "when input is [36] the target: 45\n",
      "when input is [36, 45] the target: 40\n",
      "when input is [36, 45, 40] the target: 54\n",
      "when input is [36, 45, 40, 54] the target: 55\n",
      "when input is [36, 45, 40, 54, 55] the target: 60\n",
      "when input is [36, 45, 40, 54, 55, 60] the target: 6\n",
      "when input is [36, 45, 40, 54, 55, 60, 6] the target: 0\n",
      "when input is [36, 45, 40, 54, 55, 60, 6, 0] the target: 0\n",
      "when input is [47] the target: 47\n",
      "when input is [47, 47] the target: 1\n",
      "when input is [47, 47, 1] the target: 42\n",
      "when input is [47, 47, 1, 42] the target: 50\n",
      "when input is [47, 47, 1, 42, 50] the target: 4\n",
      "when input is [47, 47, 1, 42, 50, 4] the target: 0\n",
      "when input is [47, 47, 1, 42, 50, 4, 0] the target: 10\n",
      "when input is [47, 47, 1, 42, 50, 4, 0, 10] the target: 49\n",
      "when input is [18] the target: 1\n",
      "when input is [18, 1] the target: 54\n",
      "when input is [18, 1, 54] the target: 40\n",
      "when input is [18, 1, 54, 40] the target: 40\n",
      "when input is [18, 1, 54, 40, 40] the target: 0\n",
      "when input is [18, 1, 54, 40, 40, 0] the target: 15\n",
      "when input is [18, 1, 54, 40, 40, 0, 15] the target: 50\n",
      "when input is [18, 1, 54, 40, 40, 0, 15, 50] the target: 53\n",
      "when input is [49] the target: 50\n",
      "when input is [49, 50] the target: 1\n",
      "when input is [49, 50, 1] the target: 51\n",
      "when input is [49, 50, 1, 51] the target: 53\n",
      "when input is [49, 50, 1, 51, 53] the target: 50\n",
      "when input is [49, 50, 1, 51, 53, 50] the target: 51\n",
      "when input is [49, 50, 1, 51, 53, 50, 51] the target: 43\n",
      "when input is [49, 50, 1, 51, 53, 50, 51, 43] the target: 40\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4 # how many independent sequences will we process in parallel?\n",
    "context_size = 8 # what is the maximum context length for predictions?\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - context_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+context_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+context_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('----')\n",
    "\n",
    "for b in range(batch_size): # batch dimension\n",
    "    for t in range(context_size): # time dimension\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"when input is {context.tolist()} the target: {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23426a7-fb15-46c6-b32b-6a7f72a5c77e",
   "metadata": {},
   "source": [
    "# Bigram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26abcb56-6fe2-4777-8ff1-ffb3eed59256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 62])\n",
      "tensor(4.8775, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers. get the embeddings. \n",
    "        # each index in input tensor takes out token_embeeding_table row\n",
    "        logits = self.token_embedding_table(idx) # (B,T,C)\n",
    "        B,T,C = logits.shape\n",
    "        logits = logits.view(B*T, C)\n",
    "        targets=targets.view(B*T)\n",
    "        loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "model = BigramLanguageModel(vocab_size)\n",
    "logits, loss = model(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss) # expecting ~ -ln(1/65)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d65aec2-d085-41df-863a-52b5921086b6",
   "metadata": {},
   "source": [
    "Add a generative step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc00dfa2-8460-4bec-a203-a7593d3a7897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 62])\n",
      "tensor(4.4976, grad_fn=<NllLossBackward0>)\n",
      "['\\n', 'R', 'H', 'F', 'Z', 'T', 'B', 'p', 'a', 'L', 'M', 'D', 'q', '?', 'r', 'p', ':', 'x', 'P', ';', '\\n', 'd', 'M', 'e', 'g', \"'\", 'G', 'Z', 'Y', 'J', 'y', 'D', ' ', 'R', 'f', 'S', 'l', 'X', 'k', 'H', 'q', 'r', 'E', 'J', 'X', ';', 'Z', '-', 'M', 'Z', 'b', 'C', 'v', 'W', 'j', 'm', 'B', 'V', 'o', 'z', 'h', 'Q', 'O', 's', ':', '-', 'i', '\\n', 'b', '.', 'r', 'u', 'c', 'O', 'x', 'g', 'W', 'd', 'h', 'r', 'E', 'Z', 'g', 'w', '\\n', 'r', 'a', 'Y', ':', 'i', 'Y', ',', ',', 'n', 'K', 'N', ',', ':', '.', 'U', 'C']\n"
     ]
    }
   ],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "            \n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        logits = self.token_embedding_table(idx) # (B,T,C)\n",
    "        \n",
    "        if targets is None: # targets optional for inference \n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx)\n",
    "            \n",
    "            # get most recent token \n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            \n",
    "            # softmax over vocabulary \n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            \n",
    "            # sample from the distribution to get next input \n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            \n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a0ebf12-1c04-4b72-aa09-359654e8b9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3) # 3e-4 for big network. 1e-3 for small networks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d6177d3-b93f-482f-888c-30edaf165445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3742942810058594\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(10000):\n",
    "    xb, yb = get_batch('train')\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(loss.item())\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4a747ebe-2b54-4890-b4b2-0ba677a69f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frootorst thoshe thedy\n",
      "M?\n",
      "\n",
      "Thato heto llu stweepano abod tl.thet gmpouVEvinge th.\n",
      "Anavemyondurgse I wat\n",
      "An, y geacofr teite; s e cuthay artheng,-kes eqXHAT:\n",
      "\n",
      "\n",
      "NShin! we wous send.\n",
      "And tound limed.\n",
      "Istoe ifrtyo honsete Ypofroavisour bunk ome 'dedYond CRKEDuee be te.\n",
      "apisbusoirulo oqbld fref ayed itha s,\n",
      "I shireeans tends od ingure sidss llcond,\n",
      "l be to iarrkiththere\n",
      "ABur s, se htis k.\n",
      "Sto an obun.\n",
      "poraturcitothanssh,\n",
      "MELod\n",
      "sthexanje sthe\n",
      "Timay pa fex: roDirexck y io ie s fo, momyousid w,\n",
      "\n",
      "R: be t\n"
     ]
    }
   ],
   "source": [
    "print(\"\".join(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f673e2-3721-4ca6-b910-a45f00144a50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d9fbfc-6483-456f-a9f8-c98189790206",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237e1af9-fe54-45ab-9146-b829556f9b52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bf8fe3-5567-4311-8518-47366c2a8d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad() # no storing grad chain. no backward calls \n",
    "def estimate_loss():\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ff6e8e-da59-4e18-a0b9-76c53de24fb9",
   "metadata": {},
   "source": [
    "\n",
    "### Trick for self attention\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5a1f308c-d1e2-4139-b644-8802d0b40e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,2\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ab2052-059a-4560-814b-3f4010de0679",
   "metadata": {},
   "source": [
    "x[b,t] = mean_{z<=t} x[b,i]... take mean feature vector of history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "09acd2b1-ba19-454f-904d-a1f4ed4f8863",
   "metadata": {},
   "outputs": [],
   "source": [
    "xbow = torch.zeros((B,T,C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, :t+1]\n",
    "        xbow[b,t] = torch.mean(xprev, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bb278544-6d01-4aa1-b9d4-113bfa88bb32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.3596, -0.9152],\n",
       "        [ 0.6258,  0.0255],\n",
       "        [ 0.9545,  0.0643],\n",
       "        [ 0.3612,  1.1679],\n",
       "        [-1.3499, -0.5102],\n",
       "        [ 0.2360, -0.2398],\n",
       "        [-0.9211,  1.5433]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "629c0b49-1123-4417-a99f-fdb13d4b9c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.0894, -0.4926],\n",
       "        [ 0.1490, -0.3199],\n",
       "        [ 0.3504, -0.2238],\n",
       "        [ 0.3525,  0.0545],\n",
       "        [ 0.0688, -0.0396],\n",
       "        [ 0.0927, -0.0682],\n",
       "        [-0.0341,  0.1332]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90a0b0e-2b1f-44c1-9816-8255bd457fba",
   "metadata": {},
   "source": [
    "first is first. second is average of first and second. third is average of frist, second and third"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cda5b79-6b90-48e2-9d0c-72eeedb1212f",
   "metadata": {},
   "source": [
    "can achieve this loop efficiently with a lower triangular matrix that is normalised along the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "94755ad7-d81c-4713-8c33-b4e038823723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tril(torch.ones(3,3)) \n",
    "a = a/ torch.sum(a, 1, keepdim=True)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3335a7de-f40e-40bb-986d-557ded06f608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1808, -0.0700],\n",
       "         [-0.0894, -0.4926],\n",
       "         [ 0.1490, -0.3199],\n",
       "         [ 0.3504, -0.2238],\n",
       "         [ 0.3525,  0.0545],\n",
       "         [ 0.0688, -0.0396],\n",
       "         [ 0.0927, -0.0682],\n",
       "         [-0.0341,  0.1332]],\n",
       "\n",
       "        [[ 1.3488, -0.1396],\n",
       "         [ 0.8173,  0.4127],\n",
       "         [-0.1342,  0.4395],\n",
       "         [ 0.2711,  0.4774],\n",
       "         [ 0.2421,  0.0694],\n",
       "         [ 0.0084,  0.0020],\n",
       "         [ 0.0712, -0.1128],\n",
       "         [ 0.2527,  0.2149]],\n",
       "\n",
       "        [[-0.6631, -0.2513],\n",
       "         [ 0.1735, -0.0649],\n",
       "         [ 0.1685,  0.3348],\n",
       "         [-0.1621,  0.1765],\n",
       "         [-0.2312, -0.0436],\n",
       "         [-0.1015, -0.2855],\n",
       "         [-0.2593, -0.1630],\n",
       "         [-0.3015, -0.2293]],\n",
       "\n",
       "        [[ 1.6455, -0.8030],\n",
       "         [ 1.4985, -0.5395],\n",
       "         [ 0.4954,  0.3420],\n",
       "         [ 1.0623, -0.1802],\n",
       "         [ 1.1401, -0.4462],\n",
       "         [ 1.0870, -0.4071],\n",
       "         [ 1.0430, -0.1299],\n",
       "         [ 1.1138, -0.1641]]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for above \n",
    "a = torch.tril(torch.ones(T,T)) \n",
    "a = a/ torch.sum(a, 1, keepdim=True)\n",
    "xbow2 = a @ x # (B,T,T) @ (B,T,C) ---> (B,T,C)\n",
    "xbow2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2cb99798-5d47-41cb-baca-e78603cdd8cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(xbow, xbow2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c288ded8-939f-45c9-b07e-196b7367388a",
   "metadata": {},
   "source": [
    "The idea is to switch to a weighted sum where weighting is attention. So this weghting will be learnt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107b7da6-6313-4fe4-84e0-f8d13b69f378",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

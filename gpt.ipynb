{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "191b5219-2af8-41a5-ac96-cd9f27601bb2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# GPT with character level embeddings on small shakespear dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27db1859-48ea-432f-8e40-39b5075c6314",
   "metadata": {},
   "source": [
    "# Preprocesing \n",
    "\n",
    "1. Tokenize: string -> chars \n",
    "2. Numeracilisation: chars -> index \n",
    "3. Sample context_length chunks from data.\n",
    "4. Each context_length chunk has context_length training examples. predict token_i with tokens_{<i}\n",
    "5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5dcf6c3-3589-441f-8e7a-3461990fdb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "# https://www.youtube.com/watch?v=kCc8FmEb1nY&ab_channel=AndrejKarpathy\n",
    "import torch\n",
    "\n",
    "# Load dataset\n",
    "with open(\"data/shakespear.txt\") as fn:\n",
    "    text = fn.read()\n",
    "\n",
    "# Get unique lsit\n",
    "chars = sorted(list(set(text)))\n",
    "\n",
    "vocab_size = len(chars)\n",
    "print(chars)\n",
    "print(len(chars))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e732195c-bddc-43da-9dd0-f35ef9533ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 43, 50, 50, 53]\n",
      "['h', 'e', 'l', 'l', 'o']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize. Chars -> intergers/index\n",
    "s2i = {ch: i for i, ch in enumerate(chars)}\n",
    "i2s = {i: ch for i, ch in enumerate(chars)}\n",
    "encode = lambda x: [s2i[ch] for ch in x]\n",
    "decode = lambda x: [i2s[i] for i in x]\n",
    "\n",
    "print(encode(\"hello\"))\n",
    "print(decode(encode(\"hello\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81e56715-0275-4fe1-b302-9933cd51e201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115393])\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
      "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
      "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
      "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
      "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
      "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
      "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
      "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
      "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
      "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
      "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
      "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
      "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
      "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
      "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
      "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
      "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
      "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
      "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
      "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
      "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
      "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
      "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
      "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
      "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
      "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
      "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
      "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
      "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
      "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
      "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
      "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
      "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
      "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
      "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
      "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
      "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
      "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
      "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
      "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
      "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
      "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
      "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "# Tokenize whole training set\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape)\n",
    "print(data[:1000])\n",
    "\n",
    "# Train/val\n",
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba882612-ed7f-4e72-a477-5e728a4642c7",
   "metadata": {},
   "source": [
    "How we grab an input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26b6a6f4-ce2b-4b88-8202-ba494b0617ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])\n"
     ]
    }
   ],
   "source": [
    "context_length = 8\n",
    "print(train_data[: context_length + 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aecd1af-f66a-412e-99ee-9a5907409322",
   "metadata": {},
   "source": [
    "Example of how it's auto regressive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54798b9e-5e9d-41bd-931c-c245cca9c116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using input tensor([18]) the target is : 47\n",
      "using input tensor([18, 47]) the target is : 56\n",
      "using input tensor([18, 47, 56]) the target is : 57\n",
      "using input tensor([18, 47, 56, 57]) the target is : 58\n",
      "using input tensor([18, 47, 56, 57, 58]) the target is : 1\n",
      "using input tensor([18, 47, 56, 57, 58,  1]) the target is : 15\n",
      "using input tensor([18, 47, 56, 57, 58,  1, 15]) the target is : 47\n",
      "using input tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target is : 58\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:context_length]\n",
    "y = train_data[1:context_length+1]\n",
    "for t in range(context_length):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"using input {context} the target is : {target}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b43b36-389b-4bc7-ae3f-74d5e8f920b4",
   "metadata": {},
   "source": [
    "sample minibatch: notice input encodes autoregressive style inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25eb2f84-bfc1-4120-991a-876f500a2ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[53, 59,  6,  1, 58, 56, 47, 40],\n",
      "        [49, 43, 43, 54,  1, 47, 58,  1],\n",
      "        [13, 52, 45, 43, 50, 53,  8,  0],\n",
      "        [ 1, 39,  1, 46, 53, 59, 57, 43]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[59,  6,  1, 58, 56, 47, 40, 59],\n",
      "        [43, 43, 54,  1, 47, 58,  1, 58],\n",
      "        [52, 45, 43, 50, 53,  8,  0, 26],\n",
      "        [39,  1, 46, 53, 59, 57, 43,  0]])\n",
      "----\n",
      "when input is [53] the target: 59\n",
      "when input is [53, 59] the target: 6\n",
      "when input is [53, 59, 6] the target: 1\n",
      "when input is [53, 59, 6, 1] the target: 58\n",
      "when input is [53, 59, 6, 1, 58] the target: 56\n",
      "when input is [53, 59, 6, 1, 58, 56] the target: 47\n",
      "when input is [53, 59, 6, 1, 58, 56, 47] the target: 40\n",
      "when input is [53, 59, 6, 1, 58, 56, 47, 40] the target: 59\n",
      "when input is [49] the target: 43\n",
      "when input is [49, 43] the target: 43\n",
      "when input is [49, 43, 43] the target: 54\n",
      "when input is [49, 43, 43, 54] the target: 1\n",
      "when input is [49, 43, 43, 54, 1] the target: 47\n",
      "when input is [49, 43, 43, 54, 1, 47] the target: 58\n",
      "when input is [49, 43, 43, 54, 1, 47, 58] the target: 1\n",
      "when input is [49, 43, 43, 54, 1, 47, 58, 1] the target: 58\n",
      "when input is [13] the target: 52\n",
      "when input is [13, 52] the target: 45\n",
      "when input is [13, 52, 45] the target: 43\n",
      "when input is [13, 52, 45, 43] the target: 50\n",
      "when input is [13, 52, 45, 43, 50] the target: 53\n",
      "when input is [13, 52, 45, 43, 50, 53] the target: 8\n",
      "when input is [13, 52, 45, 43, 50, 53, 8] the target: 0\n",
      "when input is [13, 52, 45, 43, 50, 53, 8, 0] the target: 26\n",
      "when input is [1] the target: 39\n",
      "when input is [1, 39] the target: 1\n",
      "when input is [1, 39, 1] the target: 46\n",
      "when input is [1, 39, 1, 46] the target: 53\n",
      "when input is [1, 39, 1, 46, 53] the target: 59\n",
      "when input is [1, 39, 1, 46, 53, 59] the target: 57\n",
      "when input is [1, 39, 1, 46, 53, 59, 57] the target: 43\n",
      "when input is [1, 39, 1, 46, 53, 59, 57, 43] the target: 0\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4 # how many independent sequences will we process in parallel?\n",
    "context_size = 8 # what is the maximum context length for predictions?\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - context_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+context_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+context_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('----')\n",
    "\n",
    "for b in range(batch_size): # batch dimension\n",
    "    for t in range(context_size): # time dimension\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"when input is {context.tolist()} the target: {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23426a7-fb15-46c6-b32b-6a7f72a5c77e",
   "metadata": {},
   "source": [
    "# Bigram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26abcb56-6fe2-4777-8ff1-ffb3eed59256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 65])\n",
      "tensor(4.8948, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers. get the embeddings. \n",
    "        # each index in input tensor takes out token_embeeding_table row\n",
    "        logits = self.token_embedding_table(idx) # (B,T,C)\n",
    "        B,T,C = logits.shape\n",
    "        logits = logits.view(B*T, C)\n",
    "        targets=targets.view(B*T)\n",
    "        loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "model = BigramLanguageModel(vocab_size)\n",
    "logits, loss = model(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss) # expecting ~ -ln(1/65)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d65aec2-d085-41df-863a-52b5921086b6",
   "metadata": {},
   "source": [
    "Add a generative step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc00dfa2-8460-4bec-a203-a7593d3a7897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 65])\n",
      "tensor(4.7525, grad_fn=<NllLossBackward0>)\n",
      "['\\n', 'h', 'b', 'H', '\\n', '\\n', ':', 'C', 'L', 'P', '.', 'A', '!', 'f', 'q', \"'\", '3', 'g', 'g', 't', '!', 'O', '!', 'T', '?', 'X', '!', '!', 'S', 'A', '?', 'W', '&', 'T', 'r', 'p', 'v', 'Y', 'y', 'b', 'S', 'E', '3', 'w', '&', 'S', ' ', 'B', 'X', 'U', 'h', 'm', 'i', 'K', 'Y', 'y', 'T', 'm', 'W', 'M', 'P', 'h', 'h', 'm', 'n', 'H', 'K', 'j', '!', '!', 'b', 't', 'g', 'n', 'w', 'N', 'N', 'U', 'L', 'u', 'E', 'z', 'R', 'u', 'Y', 'y', 'i', 'W', 'E', 'Q', 'x', 'P', 'X', '!', '$', '3', 'C', \"'\", 'M', 'B', 'j']\n"
     ]
    }
   ],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "            \n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        logits = self.token_embedding_table(idx) # (B,T,C)\n",
    "        \n",
    "        if targets is None: # targets optional for inference \n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx)\n",
    "            \n",
    "            # get most recent token \n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            \n",
    "            # softmax over vocabulary \n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            \n",
    "            # sample from the distribution to get next input \n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            \n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a0ebf12-1c04-4b72-aa09-359654e8b9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3) # 3e-4 for big network. 1e-3 for small networks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d6177d3-b93f-482f-888c-30edaf165445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5927720069885254\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(1000):\n",
    "    xb, yb = get_batch('train')\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(loss.item())\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a747ebe-2b54-4890-b4b2-0ba677a69f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MQHMdmCgtwt!ZApKKTw!O DkG3LXZBCUknouca, oy.;JolY h&Uf?wi$NUTB$Rv-FYtABSEQpa-G XpbshbHhGJQw naoGft;RH\n",
      "veBZLulpFNvXUQonpft$JYWABUYtizXe:Cr,mfGBsut;J!..g'FKMp&H!SQSG..WiswtP n;;fG-Jup:mjCrl-wLI alntQ-R-l oy t!ri?mCIaf.NY tfJ;ppbmzXPaugeUY VDkCth\n",
      "y3MMqDBLXXZ. hNUwic,b;HoSwaxqDlaS:LzLXHTEH:dzBye tolXc$ sTZE3ggxwm:hnQ!.f?\n",
      "eU'zBaWivamINahw?:,b\n",
      "hIxqNzXPnvqf fAz,ETVr'PasU$SEtvNJ!!Twcy M$KMBymbUJOWon n.y;JFviC$q3woByHp t,QHkHkRauTmhiUCWf JI:nsETHeg\n",
      "QEDdkbYjk:iiIUMK3,Q$b\n",
      "oVBWhXchbnp,3S-GL.WUXPl.WCj!'z!B$Ei\n"
     ]
    }
   ],
   "source": [
    "print(\"\".join(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f673e2-3721-4ca6-b910-a45f00144a50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d9fbfc-6483-456f-a9f8-c98189790206",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237e1af9-fe54-45ab-9146-b829556f9b52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522f24a5-6e18-4951-883a-18a8a14942c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afacfa6-49f9-4a70-bf4b-8a992f92992f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b92812-e16c-42e4-9920-8c638697fdbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25ff6e8e-da59-4e18-a0b9-76c53de24fb9",
   "metadata": {},
   "source": [
    "\n",
    "### Trick for self attention\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a1f308c-d1e2-4139-b644-8802d0b40e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,2\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ab2052-059a-4560-814b-3f4010de0679",
   "metadata": {},
   "source": [
    "x[b,t] = mean_{z<=t} x[b,i]... take mean feature vector of history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09acd2b1-ba19-454f-904d-a1f4ed4f8863",
   "metadata": {},
   "outputs": [],
   "source": [
    "xbow = torch.zeros((B,T,C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, :t+1]\n",
    "        xbow[b,t] = torch.mean(xprev, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb278544-6d01-4aa1-b9d4-113bfa88bb32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.3596, -0.9152],\n",
       "        [ 0.6258,  0.0255],\n",
       "        [ 0.9545,  0.0643],\n",
       "        [ 0.3612,  1.1679],\n",
       "        [-1.3499, -0.5102],\n",
       "        [ 0.2360, -0.2398],\n",
       "        [-0.9211,  1.5433]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "629c0b49-1123-4417-a99f-fdb13d4b9c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.0894, -0.4926],\n",
       "        [ 0.1490, -0.3199],\n",
       "        [ 0.3504, -0.2238],\n",
       "        [ 0.3525,  0.0545],\n",
       "        [ 0.0688, -0.0396],\n",
       "        [ 0.0927, -0.0682],\n",
       "        [-0.0341,  0.1332]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90a0b0e-2b1f-44c1-9816-8255bd457fba",
   "metadata": {},
   "source": [
    "first is first. second is average of first and second. third is average of frist, second and third"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cda5b79-6b90-48e2-9d0c-72eeedb1212f",
   "metadata": {},
   "source": [
    "can achieve this loop efficiently with a lower triangular matrix that is normalised along the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94755ad7-d81c-4713-8c33-b4e038823723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tril(torch.ones(3,3)) \n",
    "a = a/ torch.sum(a, 1, keepdim=True)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3335a7de-f40e-40bb-986d-557ded06f608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1808, -0.0700],\n",
       "         [-0.0894, -0.4926],\n",
       "         [ 0.1490, -0.3199],\n",
       "         [ 0.3504, -0.2238],\n",
       "         [ 0.3525,  0.0545],\n",
       "         [ 0.0688, -0.0396],\n",
       "         [ 0.0927, -0.0682],\n",
       "         [-0.0341,  0.1332]],\n",
       "\n",
       "        [[ 1.3488, -0.1396],\n",
       "         [ 0.8173,  0.4127],\n",
       "         [-0.1342,  0.4395],\n",
       "         [ 0.2711,  0.4774],\n",
       "         [ 0.2421,  0.0694],\n",
       "         [ 0.0084,  0.0020],\n",
       "         [ 0.0712, -0.1128],\n",
       "         [ 0.2527,  0.2149]],\n",
       "\n",
       "        [[-0.6631, -0.2513],\n",
       "         [ 0.1735, -0.0649],\n",
       "         [ 0.1685,  0.3348],\n",
       "         [-0.1621,  0.1765],\n",
       "         [-0.2312, -0.0436],\n",
       "         [-0.1015, -0.2855],\n",
       "         [-0.2593, -0.1630],\n",
       "         [-0.3015, -0.2293]],\n",
       "\n",
       "        [[ 1.6455, -0.8030],\n",
       "         [ 1.4985, -0.5395],\n",
       "         [ 0.4954,  0.3420],\n",
       "         [ 1.0623, -0.1802],\n",
       "         [ 1.1401, -0.4462],\n",
       "         [ 1.0870, -0.4071],\n",
       "         [ 1.0430, -0.1299],\n",
       "         [ 1.1138, -0.1641]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for above \n",
    "a = torch.tril(torch.ones(T,T)) \n",
    "a = a/ torch.sum(a, 1, keepdim=True)\n",
    "xbow2 = a @ x # (B,T,T) @ (B,T,C) ---> (B,T,C)\n",
    "xbow2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2cb99798-5d47-41cb-baca-e78603cdd8cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(xbow, xbow2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c288ded8-939f-45c9-b07e-196b7367388a",
   "metadata": {},
   "source": [
    "The idea is to switch to a weighted sum where weighting is attention. So this weghting will be learnt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107b7da6-6313-4fe4-84e0-f8d13b69f378",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c2a53d-514c-4346-9f43-a6f5b43c856f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ffb899e-537c-422a-aa75-4bc527e11246",
   "metadata": {},
   "source": [
    "## Transformer model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7d3f4a-ef2d-4ccb-872b-c24d214a1e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class FeedFoward(nn.Module):\n",
    "    \"\"\"a simple linear layer followed by a non-linearity\"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "class Head(nn.Module):\n",
    "    \"\"\"one head of self-attention\"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer(\"tril\", torch.tril(torch.ones(context_size, context_size)))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input of size (batch, time-step, channels)\n",
    "        # output of size (batch, time-step, head size)\n",
    "        B, T, C = x.shape\n",
    "        k = self.key(x)  # (B,T,hs)\n",
    "        q = self.query(x)  # (B,T,hs)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = (\n",
    "            q @ k.transpose(-2, -1) * k.shape[-1] ** -0.5\n",
    "        )  # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float(\"-inf\"))  # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1)  # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x)  # (B,T,hs)\n",
    "        out = wei @ v  # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
    "        return out\n",
    "    \n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"multiple heads of self-attention in parallel\"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)]) # list of submodules, accesed ilke normal list  \n",
    "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "    \n",
    "class Transformer(nn.Module):\n",
    "    \"\"\"Transformer block: communication followed by computation\"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x\n",
    "    \n",
    "class GPT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(context_size, n_embd)\n",
    "        self.blocks = nn.Sequential(\n",
    "            *[Transformer(n_embd, n_head=n_head) for _ in range(n_layer)]\n",
    "        )\n",
    "        self.ln_f = nn.LayerNorm(n_embd)  # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "        # better init\n",
    "        self.apply(self._init_weights)\n",
    "        \n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx)  # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device))  # (T,C)\n",
    "        x = tok_emb + pos_emb  # (B,T,C)\n",
    "        x = self.blocks(x)  # (B,T,C)\n",
    "        x = self.ln_f(x)  # (B,T,C)\n",
    "        logits = self.lm_head(x)  # (B,T,vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B * T, C)\n",
    "            targets = targets.view(B * T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last context_size tokens\n",
    "            idx_cond = idx[:, -context_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :]  # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1)  # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1)  # (B, T+1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43333a5b-528e-4b31-9ee6-31308b0c94eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad() # no gradient recording \n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in [\"train\", \"val\"]:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7400aa-4595-4a36-b626-b87731b793b8",
   "metadata": {},
   "source": [
    "Note:\n",
    "- @torch.no_grad() # no grad recording, less memory\n",
    "- model.eval(), model.train() # switching \n",
    "- different weight initalisations \n",
    "- self.apply() # init weights \n",
    "- nn.Sequential(*[Transofrmer() for in ...]) # unpacking argumetns into sequential\n",
    "- self.register_buffer # non-trainable params in model\n",
    "- nn.ModuleList # special list for modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2be1b65a-dae9-46d2-ba3b-a2854d6df776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.788929 M parameters\n"
     ]
    }
   ],
   "source": [
    "n_embd = 384 # size of embedding in attnetion\n",
    "n_layer = 6 # \n",
    "n_head = 6 # num heads in multi head attention\n",
    "batch_size = 256 \n",
    "context_size = 256 # max input \n",
    "learning_rate = 3e-4\n",
    "eval_iters= 200\n",
    "eval_interval = 500\n",
    "max_iters = 5000\n",
    "dropout = 0.2 # rate of dropout \n",
    "device = \"cuda\"\n",
    "\n",
    "\n",
    "model = GPT()\n",
    "model.to(device)\n",
    "print(sum(p.numel() for p in model.parameters()) / 1e6, \"M parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2b53a6f-28d4-4b54-bde4-9fc498125afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = model.parameters().__next__().device\n",
    "print(\"Model device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b205176-bbfd-41dc-8881-3f743a6acbce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 4.2209, val loss 4.2195\n",
      "step 500: train loss 1.5228, val loss 1.7124\n",
      "step 1000: train loss 1.2391, val loss 1.5180\n",
      "step 1500: train loss 1.0989, val loss 1.4956\n",
      "step 2000: train loss 0.9639, val loss 1.5082\n",
      "step 2500: train loss 0.8308, val loss 1.5729\n",
      "step 3000: train loss 0.7059, val loss 1.6486\n",
      "step 3500: train loss 0.5797, val loss 1.7509\n",
      "step 4000: train loss 0.4770, val loss 1.8594\n",
      "step 4500: train loss 0.3877, val loss 1.9613\n",
      "step 4999: train loss 0.3215, val loss 2.0376\n",
      "['\\n', 'A', 'p', 'o', 'l', 'l', 'o', ',', ' ', 'o', 'u', 'r', ' ', 's', 'o', 'n', ',', ' ', 't', 'a', 'k', 'e', 's', ';', ' ', 'a', 'n', 'd', ' ', 'y', 'o', 'u', 'r', ' ', 'b', 'r', 'o', 't', 'h', 'e', 'r', ' ', 'b', 'e', 'l', 'o', 'w', 's', '.', '\\n', 'I', \"'\", 'l', 'l', ' ', 'h', 'a', 'v', 'e', ' ', 'y', 'o', 'u', ' ', 'a', 'c', 'c', 'o', 's', 't', ' ', 'u', 'p', ' ', 'w', 'i', 't', 'h', ' ', 'b', 'o', 'o', 'k', ' ', 'f', 'o', 'r', 'r', \"'\", 't', '.', '\\n', '\\n', 'S', 'I', 'C', 'I', 'N', 'I', 'U', 'S', ':', '\\n', 'O', ',', ' ', 'a', 'l', 'l', ' ', 't', 'h', 'e', ' ', 'h', 'e', 'a', 'v', 'e', 'n', 'e', 's', 's', ' ', 'b', 'l', 'e', 'e', 'd', '\\n', 'Y', 'o', 'u', ' ', 'f', 'i', 'g', 'h', 't', ' ', 'i', 'n', ' ', 'm', 'i', 'n', 'e', ' ', 'a', 'c', 't', ',', ' ', 'i', 'f', ' ', 'y', 'o', 'u', ' ', 'd', 'o', ' ', 'b', 'u', 't', ' ', 'w', 'h', 'a', 't', '\\n', 'W', 'h', 'a', 't', ' ', 'y', 'e', 't', ' ', 'w', 'o', 'u', 'l', 'd', ' ', 'h', 'a', 'v', 'e', ' ', 'y', 'o', 'u', ' ', 'i', 'n', 'c', 'h', ' ', 'h', 'e', 'l', 'p', 'e', 'd', ' ', 'h', 'e', 'r', ' ', 'l', 'o', 'v', 'e', 's', '.', '\\n', '\\n', 'B', 'R', 'U', 'T', 'U', 'S', ':', '\\n', 'S', 'i', 'r', ',', ' ', 'i', 't', ' ', 'i', 's', ' ', 'a', ' ', 'l', 'a', 'm', 'y', '.', '\\n', '\\n', 'C', 'O', 'R', 'I', 'O', 'L', 'A', 'N', 'U', 'S', ':', '\\n', 'W', 'i', 'l', 'l', ' ', 't', 'h', 'e', ' ', 'c', 'o', 'm', 'e', ' ', 'l', 'a', 's', 'h', ' ', 'b', 'y', ' ', 'm', 'y', ' ', 'p', 'o', 'w', 'e', 'r', ';', ' ', 'y', 'o', 'u', ' ', 'k', 'n', 'o', 'w', ' ', 't', 'h', 'e', ' ', 'c', 'i', 't', 'y', '\\n', 'H', 'a', 'v', 'e', ' ', 'b', 'o', 'u', 'n', 'd', ' ', 't', 'o', ' ', 'e', 'a', 'c', 'h', ' ', 'p', 'a', 'r', 't', 'i', 'c', 'u', 'l', 'a', 'r', ' ', 'a', 'n', 'd', ' ', 't', 'a', 'k', 'e', ' ', 'h', 'i', 's', '\\n', 'W', 'i', 't', 'h', ' ', 's', 'p', 'a', 'c', 'i', 'n', 'g', ' ', 'a', 'n', 'd', ' ', 'm', 'a', 'j', 'e', 's', 't', 'y', ',', ' ', 'a', 'r', 'e', ' ', 'y', 'o', 'u', ' ', 'n', 'o', 't', '?', '\\n', '\\n', 'M', 'E', 'N', 'E', 'N', 'I', 'U', 'S', ':', '\\n', 'A', 'n', 'd', ' ', 'e', 'v', 'e', 'r', '\\n', 'P', 'r', 'a', 'r', 'i', 'n', 'g', ' ', 't', 'o', ' ', 'd', 'i', 'r', 'e', 'c', 't', ' ', 'p', 'r', 'e', 's', 's', ' ', 'w', 'h', 'a', 't', ' ', 'h', 'e', ' ', 's', 'i', 'n', 'g', 's', ' ', 'o', 'f', ' ', 't', 'h', 'e', ' ', 'p', 'e', 'o', 'p', 'l', 'e', ',', '\\n', 'C', 'o', 'u', 'l', 'd', ' ', 'n', 'o', 't', ' ', 'e', 'm', 'p', 't', ' ', 'o', 'f', ' ', 'h', 'i', 's', ' ', 'c', 'o', 'u', 'n', 't', 'r', 'y', \"'\", 's', ' ', 'h', 'e', 'a', 'd']\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate) # memory used by this? \n",
    "for iter in range(max_iters):\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(\n",
    "            f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\"\n",
    "        )\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch(\"train\")\n",
    "    xb = xb.to(device)\n",
    "    yb = yb.to(device)\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d85d6f9a-b3c1-4193-9382-4c3467ac63ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"gpt.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4cf1e69f-c725-4834-bcd5-fbea7c821e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Name uname throws, while I did othem\n",
      "A dream my wife to the morning.\n",
      "\n",
      "CAMILLO:\n",
      "I have help'd it so, I am comfort with light\n",
      "And talk'd of no lesss.\n",
      "\n",
      "LEONTES:\n",
      "Thou want'st woman, like men's a desight\n",
      "In this knace of imagine before my only;\n",
      "The other of other gawds each parent,\n",
      "And grift of the houndam, nice, the daught,\n",
      "When I, there lie hoope to forget through hurough\n",
      "And old now for the herd life before left our brother.\n",
      "This shall well usurp the holy seat,\n",
      "Even was thought, with a foul sorrow\n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(\"\".join(decode(model.generate(context, max_new_tokens=500)[0].tolist())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999b58f3-16e0-48d0-863e-bafd2320204d",
   "metadata": {},
   "source": [
    "# nn.Embedding layer \n",
    "\n",
    "```\n",
    "emb = nn.Embedding(vocab_size, n_embd)\n",
    "\n",
    "emb(t) # tensor is arbitary size of num of indexs to extract\n",
    "```\n",
    "\n",
    "nn.Embedding is a vocab_size x n_embd matrix. For every element of tensor argument when it's called, the index is extracted from the embedding matrix. \n",
    "\n",
    "A common pretraining for these embeddings is glove. But they can be trainable themselves. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5b644e95-3621-430e-adcd-a74a21480565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 4) -> (2, 4, 3)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "vocab_size = 10\n",
    "n_embd = 3\n",
    "\n",
    "embedding = nn.Embedding(10, 3)\n",
    "inp = torch.LongTensor([[1, 2, 4, 5], [4, 3, 2, 9]])\n",
    "embedded = embedding(inp).detach().numpy()\n",
    "print(f\"{inp.numpy().shape} -> {embedded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "719eea3e-6037-43c8-a984-d592e9b138f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding shape = (10, 3)\n"
     ]
    }
   ],
   "source": [
    "w = embedding.weight.detach().numpy()\n",
    "print(f\"embedding shape = {w.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c5f2c4db-d336-417e-96c1-1eb3f033ad0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACGAAAAMsCAYAAAARKUb3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABpbElEQVR4nOzdeZQU5dk34HuGZYYdFJBNQUBFFsUgLiigqOCGYiS4RAXcxQ3jrjGKO2hQw6KQRFTUiLu+RoMal2ii36smbjEmaJAYcV9QEUGY5/vDM/1OzwI9FDqi13UO5zDV1dV3V1dVP89Tv64qSimlAAAAAAAAAABgtRXXdQEAAAAAAAAAAGs7AQwAAAAAAAAAgIwEMAAAAAAAAAAAMhLAAAAAAAAAAADISAADAAAAAAAAACAjAQwAAAAAAAAAgIwEMAAAAAAAAAAAMhLAAAAAAAAAAADISAADAAAAAAAAACCjWgUwrrvuuigqKoo33njjGyrnh22HHXaIHXbY4Vt9jTfeeCOKioriuuuuy7zsMWPGRJcuXTIv55te5g9Rly5dYsyYMd/66y5fvjxOO+20WH/99aO4uDhGjBjxrdfwXXTeeedFUVFRfPDBB9/4axV6XHnssceiqKgoHnvssdw0+x8A1F5RUVEcd9xx3/jrVPfdXZNvsg9QW7Wpe3V9m22tb8KkSZOiR48eUVZWVtelFKRLly6x5557fmPL/za2mbXVN73uy9XmmFFdH6KoqCjOO++8b6S21fFt9X222WabOO2009boMgFYuXnz5sXQoUOjRYsWUVRUFHfffXed1PFtjPN/W/2Otc0OO+wQvXv3Xu3nfxPj6HU1Nl+ozz//PA4//PBo165dFBUVxfjx42uc97v+XlamvE17+eWX13Up37pCjxffxfMW3ye12de+C75r/bi1zVp9BYxXXnklzjvvvO9cIGThwoVx3nnnxfPPP1/XpbCaLr744jproK/Md3Wbr8m1114bl112WYwcOTKuv/76OOmkk+q6JAAA+M769NNPY+LEiXH66adHcfFa3V2HH7zTTz89pk2bFu+8805dlwLwgzF69Oh46aWX4qKLLorZs2fHlltuGTfffHNceeWVdV0afGddfPHFcd1118UxxxwTs2fPjoMPPriuSyrY9OnT6+SHBbA61uZ97fvoww8/jMsuuywGDRoUbdq0iZYtW8Y222wTc+bMWSPLr1+bmQ8++ODYf//9o6SkZI28eFavvPJKTJgwIXbYYYfv1K+0Fy5cGBMmTIguXbpE3759C37egw8++M0VVcNrdO7cOZYsWRINGjTIvOxf//rXa82vtFbl4osvjpEjR37nrtiwutv8P//5zzoZwH3kkUeiY8eOccUVV3zrr01236d9GgD4P2uyD8Cade2118by5cvjgAMOqOtSvjMGDRoUS5YsiYYNG9Z1KaymJUuWRP36tRp++tZ9E32fvffeO5o3bx7Tp0+P888/f40uG4CqlixZEk899VScffbZeb/0vvnmm+Pll1/+zv/SmO+GuhpHr0uPPPJIbLPNNnHuueeuct7v2vqZPn16tG7deq29Kgc/LLXZ174L1oZ+XBblbYbdd989fv7zn0f9+vXjjjvuiP333z93LjaLWh0p69WrF6WlpVFUVJTpRcn3xRdfREREw4YNv/FBpcqvUVRUFKWlpVGvXr3My27QoMF3Jpyztli+fHksW7bsG1l2SimWLFkSERElJSV1MsD+3nvvRcuWLVc53ze5Hlh99mkA+H5ak30A1qxZs2bFXnvtFaWlpXVdyndGcXFxlJaWfqcGeqmd0tLS7/zA3TfR9ykuLo6RI0fGDTfcECmlNbpsAKp6//33IyIKGovMqqysLL788stv/HX49tXVOHpdKnQMP+KHuX6+axx/slm8eHGdvXah+9qXX375nfhh7NrQj8uiV69eMW/evLj77rvjxBNPjGOPPTb++Mc/xpAhQ2LixImZt5VajWBcd911UVRUlHf7g/J7jj755JOx1VZbRWlpaXTt2jVuuOGGap/7pz/9KY466qhYd911o3nz5nHIIYfExx9/nDdvTfeVqXh/qeuuuy5+8pOfRETEjjvuGEVFRau8L+yYMWOiadOm8Z///Cf23HPPaNq0aXTs2DGmTZsWEREvvfRSDBkyJJo0aRKdO3eOm2++Oe/5H330UZxyyinRp0+faNq0aTRv3jx22223eOGFF3LzPPbYY9G/f/+IiBg7dmyurvLLIJXfg+y5556LQYMGRePGjeOss87KPVbxnkejR4+O0tLS+Mc//pFXx7Bhw6JVq1axcOHCGt9rTb7J+z9XvmdqxXtqzZw5M7p16xYlJSXRv3//eOaZZ6o8/+67747evXtHaWlp9O7dO+66665qX6esrCyuvPLK6NWrV5SWlsZ6660XRx11VN52dO6550ZxcXH88Y9/zHvukUceGQ0bNsz7zCorKiqKxYsXx/XXX5/7/ComKP/2t7/FbrvtFs2bN4+mTZvGTjvtFE8//fQq10/F9XHllVfm1scrr7wSERGvvvpqjBw5MtZZZ50oLS2NLbfcMu69997c81e1zZfvi3Pnzo0tt9wyGjVqFDNmzMg9Vv4enn322SgqKorrr7++So1z586NoqKiuO+++3LT3nrrrTj00ENjvfXWi5KSkujVq1dce+21Bb3XRx99NP7+97/n1bqq9fDII4/EwIEDo0mTJtGyZcvYe++9q+wD5fci+9e//hUHHXRQtGjRItq0aRPnnHNOpJTizTffzP3aqF27dvHLX/5ylZ9PuRtvvDH69esXjRo1inXWWSf233//ePPNN/PmKd+PX3zxxRg8eHA0btw4unfvHrfffntERDz++OOx9dZbR6NGjWKTTTaJhx9+uNrX+uCDD2LUqFHRvHnzWHfddePEE0+stvFUSE0RkdvPGjVqFFtttVU88cQT1b7uf//73xgxYkQ0adIk2rZtGyeddFIsXbq0ynxZ9+nbbrstevbsmbdPV3dv5VtuuSX69esXzZo1i+bNm0efPn3iqquuqrZ2AFhdhbRpHnvssSgqKopbb701JkyYEB07doxmzZrFyJEjY9GiRbF06dIYP358tG3bNpo2bRpjx46t9js0IuKmm26KTTbZJEpLS6Nfv37xpz/9abVqiij8uzuisPZAdX2A8r7SW2+9FSNGjIimTZtGmzZt4pRTTokVK1bkPf/DDz+Mgw8+OJo3bx4tW7aM0aNHxwsvvJCpX3Hbbbfl2jutW7eOgw46KN56660q8xXSVqzOggULonv37tG7d+949913q+3bRvzfNlCxX1mxDzdgwIBo1KhRbLjhhnHNNdes1nutyfz58+PFF1+MnXfeOTftq6++inXWWSfGjh1bZf5PP/00SktL45RTTslNe++99+Kwww6L9dZbL0pLS2PzzTevtt1fVlYWV111VfTp0ydKS0ujTZs2seuuu8azzz6bm2fWrFkxZMiQaNu2bZSUlETPnj3j6quvrrH+Bx98MPr27RulpaXRs2fPuPPOOwt636tqC1b+TMo/u+r+Vb6HcKHt6IqWLFkSPXr0iB49euQC7RFfjwe0b98+BgwYUGWfqOyTTz6J8ePHx/rrrx8lJSXRvXv3mDhxYt4gWsW29bRp06Jr167RuHHjGDp0aLz55puRUooLLrggOnXqFI0aNYq99947Pvroo2pfr5B1X0hN5fONGTMmWrRokdu/P/nkk2pft9A+fOUxnvL+3GuvvRZjxoyJli1bRosWLWLs2LG5H6iUW7JkSZxwwgnRunXraNasWey1117x1ltvFXw/4jXR98ny+eyyyy6xYMECt6gFyGDBggUxbty42GSTTaJRo0ax7rrrxk9+8pO8dtx5550XnTt3joiIU089NYqKiqJLly6xww47xO9///tYsGBBrr1Q8Xi/dOnSOPfcc6N79+5RUlIS66+/fpx22mlVviuKioriuOOOi5tuuil69eoVJSUl8Yc//KFW76PQdtrixYvj5JNPzn1nb7LJJnH55ZcXFOa78MILo7i4OKZMmRIR+WPCFVU+R1De3pozZ06cddZZ0a5du2jSpEnstddeq2w7rUyh67c27c4HHnggBg8enGs79u/fv8p5nIivryS94447RuPGjaNjx44xadKkgmquvM7K255//vOf42c/+1m0adMmmjRpEvvss08u9FMupRQXXnhhdOrUKRo3bhw77rhj/P3vf6/2dVbVNkspxY477hht2rSJ9957L/e8ZcuWRZ8+faJbt26rPDm4qm2u/HOfP39+/P73v8/tIyu7/XmW9VN+/mJVbdfytmJllftwXbp0ib///e/x+OOP19gfqMmqxrZffPHFGDNmTHTt2jVKS0ujXbt2ceihh8aHH36YN99nn30W48ePjy5dukRJSUm0bds2dtlll/jrX/+6yhoee+yx2HLLLaO0tDS6desWM2bMqPa9r+z4c/nll8eAAQNi3XXXjUaNGkW/fv1y5yiqU8g4RUTdnbeoTm37pRWVj3O8/vrrsfvuu0ezZs3ipz/9aUQUdqz98Y9/HD/60Y/yljl8+PAoKirKO3f3//7f/4uioqJ44IEHqq1jZfta+WO33HJL/PznP4+OHTtG48aN49NPP42IwsZKsp77rknlPlch38cR/7evPvnkk3HCCSfkbu9x1FFHxbJly+KTTz6JQw45JFq1ahWtWrWK0047rcp3XG3GnVZ1brUmG264Ya7tUPE9jxgxIpYuXRr//ve/C1pPNUq1MGvWrBQRaf78+blpnTt3Tptssklab7310llnnZWmTp2afvSjH6WioqL08ssvV3lunz590sCBA9OvfvWrdOyxx6bi4uI0aNCgVFZWlps3ItK5555b5fU7d+6cRo8enVJK6fXXX08nnHBCioh01llnpdmzZ6fZs2end955p8b6R48enUpLS1PPnj3T0UcfnaZNm5YGDBiQIiLNmjUrdejQIZ166qlpypQpqVevXqlevXrp3//+d+75zzzzTOrWrVs644wz0owZM9L555+fOnbsmFq0aJHeeuutlFJK77zzTjr//PNTRKQjjzwyV9frr7+eUkpp8ODBqV27dqlNmzbp+OOPTzNmzEh333137rHBgwfnXu/jjz9OnTp1Sv3790/Lly9PKaV0zTXXpIhIs2fPLuxDq6Tya8yfPz/3/st9+eWX6f333y/oX+X127lz5yrL3mKLLVL37t3TxIkT06RJk1Lr1q1Tp06d0rJly3Lzzp07NxUXF6fevXunyZMnp7PPPju1aNEi9erVK2+ZKaV0+OGHp/r166cjjjgiXXPNNen0009PTZo0Sf37988tc9myZWmLLbZInTt3Tp9++mlKKaU//OEPKSLSBRdcsNJ1NHv27FRSUpIGDhyY+/z+8pe/pJRSevnll1OTJk1S+/bt0wUXXJAuvfTStOGGG6aSkpL09NNPr3S55eujZ8+eqWvXrunSSy9NV1xxRVqwYEF6+eWXU4sWLVLPnj3TxIkT09SpU9OgQYNSUVFRuvPOO1NKq97mO3funLp3755atWqVzjjjjHTNNdekRx99NPdY+b6TUkpdu3ZNu+++e5Uax44dm1q1apVbj++8807q1KlTWn/99dP555+frr766rTXXnuliEhXXHFFje/1888/T7Nnz049evRInTp1yqt1ZevhoYceSvXr108bb7xxmjRpUpowYUJq3bp1atWqVd5x59xzz00Rkfr27ZsOOOCANH369LTHHnukiEiTJ09Om2yySTrmmGPS9OnT03bbbZciIj3++OMr/XxSSunCCy9MRUVFab/99kvTp0/PvX6XLl3Sxx9/nJtv8ODBqUOHDmn99dfPHTN69uyZ6tWrl2655ZbUrl27dN5556Urr7wyd4wo3w4r1t+nT580fPjwNHXq1HTQQQeliEgHH3zwatX0m9/8JkVEGjBgQPrVr36Vxo8fn1q2bJm6du2at89/8cUXaeONN06lpaXptNNOS1deeWXq169f2myzzVJE5LaZlLLt0/fdd18qKipKm222WZo8eXI655xzUqtWrVLv3r3zlvnggw+miEg77bRTmjZtWpo2bVo67rjj0k9+8pNVfl4AUKhC2zSPPvporo2x7bbbpl/96lfphBNOSEVFRWn//fdPBx54YNptt93StGnT0sEHH5wiIk2YMCHvtSIi9e7dO7Vu3Tqdf/75aeLEialz586pUaNG6aWXXqp1TbX57i60PVBdH6C8r9SrV6906KGHpquvvjrtu+++KSLS9OnTc/OtWLEibbvttqlevXrpuOOOS1OnTk277LJL2nzzzassszrl67hi3eV9xf79+6crrrginXHGGalRo0ZV2ju1bSuW91dee+21tMEGG6S+ffvmplXXt62pvvK2X9u2bdNxxx2XfvWrX6Xtt98+RUT67W9/u9L3Wxs33nhjioj04osv5k0/9NBDU8uWLdPSpUvzpl9//fUpItIzzzyTUvp6W9l0001TgwYN0kknnZR+9atfpYEDB6aISFdeeWXec8eMGZMiIu22227pyiuvTJdffnnae++905QpU3Lz9O/fP40ZMyZdccUVacqUKWno0KEpItLUqVPzltW5c+e08cYbp5YtW6YzzjgjTZ48OfXp0ycVFxenBx98cKXvuZC2YOXP5PXXX8/1L8r/XXjhhSki8p5XaDu6Ok8//XSqV69eOumkk3LT9t9//9SoUaP0z3/+c6XPXbx4cdpss83Suuuum84666x0zTXXpEMOOSQVFRWlE088MTdf+X7Yt2/f1LNnzzR58uT085//PDVs2DBts8026ayzzsrty+XHobFjx67Wui+0prKysjRo0KBUXFycxo0bl6ZMmZKGDBmSO95U3L9r04evPMZTvo9uscUW6cc//nGaPn16Ovzww1NEpNNOOy3vuaNGjcr1k6ZNm5ZGjRqVO95UN25U0Zro+2T5fFJK6b///W+KiLx9C4Daue2229Lmm2+efvGLX6SZM2ems846K7Vq1Sp17tw5LV68OKWU0gsvvJCuuOKKFBHpgAMOSLNnz0533XVXevDBB1Pfvn1T69atc+2Gu+66K6X0dbt26NChqXHjxmn8+PFpxowZ6bjjjkv169dPe++9d14NEZE23XTT1KZNmzRhwoQ0bdq09Le//a3GmiuPwRfaTisrK0tDhgxJRUVF6fDDD09Tp05Nw4cPTxGRxo8fX6WmY489Nvf32WefnYqKitLMmTNz0yqPCddUX3l7q0+fPrmxvDPOOCOVlpamjTfeOH3xxRc1vtea1Gb9FtrunDVrVioqKkq9e/dOF110UZo2bVo6/PDD88ZTK47bnnjiiWn69OlpyJAhKSLS/fffv8q6K6+z8n7DFltskYYMGZKmTJmSTj755FSvXr00atSovOf+/Oc/TxGRdt999zR16tR06KGHpg4dOqTWrVvnLbPQttm///3v1LRp07TPPvvkpp1xxhmpqKholWPdhWxz77zzTpo9e3Zq3bp16tu3b24f+fzzz7+R9VNo27W8rVhZ5T7cXXfdlTp16pR69OiRq31l/Y/ajG1ffvnlaeDAgen8889PM2fOTCeeeGJq1KhR2mqrrfLOZR544IGpYcOG6Wc/+1n6zW9+kyZOnJiGDx+ebrzxxhrrSCmlv/71r6mkpCR16dIlXXrppemiiy5KHTp0yLVzK1rZ8adTp05p3LhxaerUqWny5Mlpq622ShGR7rvvvirLKGScoi7PW9Sk0ONDdUaPHp1KSkpSt27d0ujRo9M111yTbrjhhoKPtZMnT07FxcVp0aJFKaWvj9GtWrVKxcXF6ZRTTsnNd9lll+XNV9nK9rXy42/Pnj1T37590+TJk9Mll1ySFi9eXPBYSdZz3zWp3Ocq5Ps4pf/bV/v27Zt23XXXvDG00047LW2//fbpwAMPTNOnT0977rlnioh0/fXX555fm3GnQs6t1tZZZ52VIiItXLhwtZ5fbo0EMCIi/elPf8pNe++991JJSUk6+eSTqzy3X79+eQeySZMmpYhI99xzz/8VVUAAI6WvP+zKneaVGT16dIqIdPHFF+emffzxx6lRo0apqKgo3XLLLbnpr776apU6vvzyy7RixYq8Zc6fPz+VlJSk888/PzftmWeeqXHwcfDgwSki0jXXXFPtY5UPOHPnzk0RkS688MLcF+6IESMKer/VKSSAUf5ZFfKvopoGLNZdd9300Ucf5abfc889KSLS//zP/+Sm9e3bN7Vv3z598sknuWnlg3EVl/nEE0+kiEg33XRT3muXhysqTn/ppZdSw4YN0+GHH54+/vjj1LFjx7Tlllumr776apXrqUmTJtU2TkeMGJEaNmyYC9SklNLChQtTs2bN0qBBg1a6zPL10bx58/Tee+/lPbbTTjulPn36pC+//DI3raysLA0YMCBttNFGuWkr2+bL98U//OEP1T5W8f2ceeaZqUGDBnmfy9KlS1PLli3ToYcempt22GGHpfbt26cPPvggb3n7779/atGixSob34MHD069evUqeD307ds3tW3bNn344Ye5aS+88EIqLi5OhxxySG5aeUPgyCOPzE1bvnx56tSpUyoqKkqXXnppbnr5Pl7d51nRG2+8kerVq5cuuuiivOkvvfRSql+/ft708v345ptvzk0rP2YUFxfnhXHK9+GK+1h5/XvttVfea40bNy5FRHrhhRdqVdOyZctS27ZtU9++ffMG5mfOnJkiIm+fv/LKK1NEpFtvvTU3bfHixal79+4FD0IWsk/36dMnderUKX322We5aY899liVffrEE09MzZs3z4XMAOCbUGibprzj27t377w+ywEHHJCKiorSbrvtlvf8bbfdttoTjRGRnn322dy0BQsWpNLS0ryBs0JrKvS7uzbtgZoCGBGR169JKaUtttgi9evXL/f3HXfcUWWgeMWKFblBzdoGMMrr7t27d1qyZEluvvvuuy9FRPrFL36Rm1bbtuL777+f/vGPf6QOHTqk/v3757VfahvAiIj0y1/+Mjdt6dKluXoqbitZlA/YVmw/pfR/7cmKba2UUtp9991T165dc3+XbysVB/uWLVuWtt1229S0adNcIPiRRx5JEZFOOOGEKjVUHEysrq0/bNiwvNdM6f/6IXfccUdu2qJFi1L79u3TFltssdL3XEhbsLrPpKIlS5akfv36pQ4dOqS33347pVS7tn1NzjzzzFRcXJz+9Kc/5fphlYMs1bngggtSkyZN0r/+9a+86WeccUaqV69e+s9//pNS+r/9sE2bNnn94DPPPDNFRNp8883z+q4HHHBAatiwYV6fsdB1X2hNd999d4qINGnSpNw8y5cvzw3WV9y/C+3Dp1RzAKNi3zOllPbZZ5+07rrr5v5+7rnnqj3hVB4gWlUAY030fbJ8PuUaNmyYjjnmmJXWCkDNqmuTPPXUUyki0g033JCbVn7svuyyy/Lm3WOPPap8N6X09Y/wiouL0xNPPJE3vfwHkH/+859z08rH/P7+978XVHPlMfhC22nl38UXXnhh3vJGjhyZioqK0muvvZZXU3kA4+STT07FxcXpuuuuy3tebQMYHTt2zPsR2a233poiIl111VUFve+KarN+C2l3fvLJJ6lZs2Zp6623zus3pJTfhi1vu1fcNpYuXZratWuX9t1331XWXVPAYOedd857nZNOOinVq1cv10547733UsOGDdMee+yRN1/5ibyKyyy0bZZSSjNmzMhtO+Uh4cpto+oUus2Vv+c99thjlcssn3d11k/5cwtpuxYawEgppV69ehV0Ej+l2o1tV7dN/u53v6tyLrRFixZ5QahCDR8+PDVu3Dj3w+6UUpo3b16qX79+tQGMmo4/letctmxZ6t27dxoyZEiVZRQyTlGX5y1qUmi/tDrl4xxnnHFG3vRCj7Xl53rLw1svvvhiivg6+L/11lvnnrfXXnutsu+bUvX7Wvnxt2vXrnnvtTZjJVnPfdek8nyFfh+X76vDhg3LOy5su+22qaioKB199NG5aeXn9SpuC7UZdyr03GqhPvzww9S2bds0cODAWj+3sjVyE9WePXvGwIEDc3+3adMmNtlkk2ovz3HkkUfm3SPqmGOOifr168f999+/JkopyOGHH577f8uWLWOTTTaJJk2axKhRo3LTN9lkk2jZsmXeeygpKcndd3bFihXx4YcfRtOmTWOTTTYp6JJCFZdT3SVkqzN06NA46qij4vzzz48f//jHUVpamrutxDdl2LBh8dBDDxX0rxD77bdftGrVKvd3+bZSvm7ffvvteP7552P06NHRokWL3Hy77LJL9OzZM29Zt912W7Ro0SJ22WWX+OCDD3L/+vXrF02bNo1HH300N2/v3r1jwoQJ8Zvf/CaGDRsWH3zwQVx//fWrfc+iFStWxIMPPhgjRoyIrl275qa3b98+DjzwwHjyySdzlwVamX333TfatGmT+/ujjz6KRx55JEaNGhWfffZZ7j19+OGHMWzYsJg3b161l1+uzoYbbhjDhg1b5Xz77bdffPXVV3mX93rwwQfjk08+if322y8iIlJKcccdd8Tw4cMjpZS3vocNGxaLFi2q1XZfWeX1UL4djBkzJtZZZ53c9M022yx22WWXao8RFfflevXqxZZbbhkppTjssMNy08v38VVdLujOO++MsrKyGDVqVN57bdeuXWy00UZ521ZERNOmTWP//ffP/V1+zNh0001j6623zk0v/391r3/sscfm/X388cdHROTea6E1Pfvss/Hee+/F0UcfHQ0bNswtr/zSwRXdf//90b59+xg5cmRuWuPGjePII49c6fqpaFX79MKFC+Oll16KQw45JJo2bZqbb/DgwdGnT5+8ZbVs2TIWL15c8PEEAGprddo0hxxySF6fZeutt46UUhx66KF582299dbx5ptvxvLly/Omb7vtttGvX7/c3xtssEHsvffeMXfu3FixYkWtair0u7s27YGVOfroo/P+HjhwYF475g9/+EM0aNAgjjjiiNy04uLiKu2aQpXXPW7cuCgtLc1N32OPPaJHjx7x+9//PiJWr6348ssvx+DBg6NLly7x8MMP57Vfaqt+/fpx1FFH5f5u2LBhHHXUUfHee+/Fc889t9rLrejDDz+M+vXr57WfIiKGDBkSrVu3jjlz5uSmffzxx/HQQw/l2u4RX28r7dq1iwMOOCA3rUGDBnHCCSfE559/Ho8//nhERNxxxx1RVFQU5557bpUaKl7utlGjRrn/L1q0KD744IMYPHhw/Pvf/45FixblPa9Dhw6xzz775P4uv93o3/72t3jnnXdqfM9roi04bty4eOmll+KOO+6Idu3aRUTt2/bVOe+886JXr14xevToGDduXAwePDhOOOGEVT7vtttui4EDB0arVq3yXnvnnXeOFStWVLnM709+8pO8fbS8/3DQQQfl9V233nrrWLZsWZW+YSHrvtCa7r///qhfv34cc8wxueXVq1cv108pV5s+/MpUd7z58MMPc/3q8ksrjxs3Lm++yvXUZE30fbJ+PhGRW+8ArJ6KbZKvvvoqPvzww+jevXu0bNky09jkbbfdFptuumn06NEj7/txyJAhERFV2guDBw+u1fdcRYW20+6///6oV69elTbHySefHCmlKpe3TynFcccdF1dddVXceOONMXr06NWqr9whhxwSzZo1y/09cuTIaN++/Wqdu6nN+i2k3fnQQw/FZ599FmeccUZevyEiqtyyoWnTpnHQQQfl/m7YsGFstdVWmS4nf+SRR+a9zsCBA2PFihWxYMGCiIh4+OGHY9myZXH88cfnzTd+/Pgqy6pNe/HII4+MYcOGxfHHHx8HH3xwdOvWLS6++OJV1lvoNremrGr9lFvdfsOatKqx7Yj8bfLLL7+MDz74ILbZZpuIiLzjTsuWLeP//b//FwsXLiz49VesWBEPP/xwjBgxIjp06JCb3r1799htt92qfU5Nx5+KdX788cexaNGiGDhwYLXHxlWNU1RUF+ctalKbfmlNKvZvyt9HIcfaLbbYIpo2bZrbJ5944ono1KlTHHLIIfHXv/41vvjii0gpxZNPPpl3jnx1jB49Ou+9FjpWUtHqnvsuVG2/jw877LC840L52FrF83fl5/VWZ9xpTZ5bjfj6Vq0//elP45NPPsndyiuL1TsTXckGG2xQZVqrVq3i448/rjJ9o402yvu7adOm0b59+5XeV2pNKr+/bUUtWrSITp06VfmibtGiRd57KL9P7vTp02P+/Pl5B6V111234Bo6duyYd7BZlcsvvzzuueeeeP755+Pmm2+Otm3bFvzc1dG+ffto3779Glte5e2j/MutfN2WfwlX3jYiokq4Zd68ebFo0aIa10HF+6FFfH3Pv1tuuSX+93//Ny6++OLVbiRHRLz//vvxxRdfxCabbFLlsU033TTKysrizTffjF69eq10ORtuuGHe36+99lqklOKcc86Jc845p9rnvPfee9GxY8dV1lh52TXZfPPNo0ePHjFnzpzcwW7OnDnRunXrXCP4/fffj08++SRmzpwZM2fOrLGu1VW51vLtoKb1O3fu3Fi8eHE0adIkN73yttWiRYsoLS2N1q1bV5le+f5slc2bNy9SStVuhxGRdxImImo8Zqy//vpVpkVEQcfDbt26RXFxce54WGhNNe1DDRo0yAsLlc/bvXv3KrVXt95rUug+3b179yrP7d69e94+PW7cuLj11ltjt912i44dO8bQoUNj1KhRseuuuxZcDwCszOq0aaprY0REtd/zZWVlsWjRorz+QHXf3RtvvHF88cUX8f7770dxcXHBNRX63V2b9kBNqusrVe7XLViwINq3bx+NGzfOm6+67/1CrKwN2KNHj3jyySdXOV9NbcXhw4fHeuutF3Pnzq0SaqitDh065C074uvPNCLijTfeyA3GfRPq168f++67b9x8882xdOnSKCkpiTvvvDO++uqrvADGggULYqONNsr9aKDcpptumns8IuL111+PDh065AVZqvPnP/85zj333Hjqqafiiy++yHts0aJFeQNm1W2jFddPeTCisqxtwRkzZsSsWbNixowZeZ9Bbdv21WnYsGFce+210b9//ygtLY1Zs2ZVey/qyubNmxcvvvhilX2pXJbjTUTVfkUh677Qmsr378r7S6HHm/J5Cz0ZtrJ+RfPmzWPBggVRXFxcpe9Y6PHmm+j71Pbzifj65Fgh2w4A1VuyZElccsklMWvWrHjrrbfy7hNf6Mm36sybNy/+8Y9/FPydXei4a3UKbactWLAgOnTokBeCqG6+cjfccEN8/vnncfXVV+edaF9dlb/bi4qKonv37qt17qY267eQdufrr78eEV//6HJVqhu3bdWqVbz44ou1fRs5q3uOo02bNlWC4LVtL/72t7+Nbt26xbx58+Ivf/lL3knQmhS6za0pq1o/5Va337AmFVLrRx99FBMmTIhbbrmlyudR8bgzadKkGD16dKy//vrRr1+/2H333eOQQw5ZaR/8vffeiyVLltQ4dl6dmo4/9913X1x44YXx/PPPx9KlS3PTq2t7rmqcouK6r4vzFjWpTb+0OvXr149OnTrlTSv0WFuvXr3Ydttt44knnoiIrwMYAwcOjO233z5WrFgRTz/9dKy33nrx0UcfZQ5g1OZ8WcWxknJZzn0Xqrbfx7XpS63OuNOaPLca8XXQ6A9/+EPccMMNsfnmmxf0nJVZIwGMevXqVTu94spfEyqnsFZHTbUW8h4uvvjiOOecc+LQQw+NCy64INZZZ50oLi6O8ePHR1lZWcE1FPIFWdHf/va33EH+pZdeWiONqZVZsmRJwY3XQr4Q1+T2UVZWFm3bto2bbrqp2scrH2D+/e9/x7x58yLi63X3XVD58y/fdk455ZQar15R6ABTbbat/fbbLy666KL44IMPolmzZnHvvffGAQcckPsVT3ldBx10UI3p6c0226zg18tSa02q27ZWd3srKyuLoqKieOCBB6pdRuVByCzHkppU/iKsbU3fljW5T7dt2zaef/75mDt3bjzwwAPxwAMPxKxZs+KQQw6J66+/PmupALBabZpv4ns+a03fhpre39pq3333jeuvvz5uuummvKtXRFQ/IBWxZvqcq2vdddeN5cuXx2effVZlIGj//fePGTNmxAMPPBAjRoyIW2+9NXr06LFGBgWq8/rrr8dOO+0UPXr0iMmTJ8f6668fDRs2jPvvvz+uuOKKWvV/VyZLW/B///d/48QTT4zDDz+8yhUN1lQ7eu7cuRHx9a/e5s2bV9CJl7Kysthll13itNNOq/bx8gHmct/08WZ1avq2fFtjSVmsic/nk08+qfIjAQAKd/zxx8esWbNi/Pjxse2220aLFi2iqKgo9t9//0xtkrKysujTp09Mnjy52scrnyBaE2OZa9p2220Xzz//fEydOjVGjRpVJWC7sjbvN932L3T9fhPtzm+ijVGXbbPHHnssd3L9pZdeim233bbWr/lNW5Pr55vuqxVS66hRo+Ivf/lLnHrqqdG3b99o2rRplJWVxa677pq3TY4aNSoGDhwYd911Vzz44INx2WWXxcSJE+POO++s8WoWq6O6488TTzwRe+21VwwaNCimT58e7du3jwYNGsSsWbPi5ptvXmOvHVF35y3WxPGh4p0NVsf2228fF110UXz55ZfxxBNPxNlnnx0tW7aM3r17xxNPPBHrrbdeRETmAEbW75hvo19Z2+/j2tS0usfSiDVzbnXChAkxffr0uPTSS+Pggw+udS3VWSMBjNqYN29e7Ljjjrm/P//883j77bdj9913z01r1apVfPLJJ3nPW7ZsWbz99tt5077tXxDcfvvtseOOO8Zvf/vbvOmVO9Nrsq7FixfH2LFjo2fPnjFgwICYNGlS7LPPPtG/f/819hqVzZkzp+BbpKyJgZHOnTtHROSCEhX985//zPu7W7du8fDDD8d22223ygNSWVlZjBkzJpo3bx7jx4+Piy++OEaOHBk//vGPV1lTdZ9hmzZtonHjxlVqioh49dVXo7i4uErDvBDlSb8GDRrEzjvvXOu6Vtd+++0XEyZMiDvuuCPWW2+9+PTTT/NuqdGmTZto1qxZrFixYpV1rQnl20FN67d169ZVfnW4JnXr1i1SSrHhhht+awOQlQdxX3vttSgrK4suXbrUqqaK+1D5FUwivr4M1Pz58/MG5jt37hwvv/xylV9hVbfeV1d5Pa+99lqVx6qb1rBhwxg+fHgMHz48ysrKYty4cTFjxow455xzVvvXtABQ7ttu00RU367917/+FY0bN84FhgutqdDv7tq0B7Lo3LlzPProo/HFF1/k/Rqhuu/4QpcX8fX7qVh3+bTyx1enrXjZZZdF/fr1Y9y4cdGsWbM48MADc4+V/8qpcr+zpl+CLVy4sMoVNv71r39FROTabln16NEjIiLmz59fJYAzaNCgaN++fcyZMye23377eOSRR+Lss8/Om6dz587x4osvRllZWd4A06uvvpp7POLrNubcuXPjo48+qvEqGP/zP/8TS5cujXvvvTfvVys13bqj/JcnFbfRQtfP6rQF33///Rg5cmT07ds3pk2bVuXxNdG2f/HFF+P888+PsWPHxvPPPx+HH354vPTSS6v8hVW3bt3i888//9aON4Ws+0Jr6ty5c/zxj3+Mzz//PG/QdGXHm8rWdL+irKws5s+fn/eruUKPN99G32dV3nrrrVi2bFnu13QA1N7tt98eo0ePjl/+8pe5aV9++WWVdlxNahpP7datW7zwwgux0047fePnGQptp3Xu3DkefvjhKoHcyvOV6969e0yaNCl22GGH2HXXXeOPf/xj3vOqO88S8XWbt7pfn1f+bk8pxWuvvbZa4fBC12+h7c5u3bpFxNe3GfwujhdWbB9VXLfvv/9+lV+a16a9+Pbbb8fxxx8fQ4cOjYYNG+ZONFbeFqqrp5Bt7ttWSNu1Yl+tZcuWufmq66t9E/vuxx9/HH/84x9jwoQJ8Ytf/CI3vbq2b8TXV5QfN25cjBs3Lt5777340Y9+FBdddFGNAYy2bdtGaWlpwWPnNbnjjjuitLQ05s6dGyUlJbnps2bNqnb+QsYpKs77bZ+3qE5t+6WFqs2xduDAgbFs2bL43e9+F2+99VYuaDFo0KBcAGPjjTfOBTHWlELHSr5NWb+PC1XouFNtzq2uzLRp0+K8886L8ePHx+mnn77ay6ls9WM/q2nmzJnx1Vdf5f6++uqrY/ny5XkHo27dulW5L+rMmTOrJNzKB7/W9Idbk3r16lUJHNx2221V7iGzJus6/fTT4z//+U9cf/31MXny5OjSpUuMHj0673JCX331Vbz66qtVAiqra9iwYfHQQw8V9G9NaN++ffTt2zeuv/76vCtvPPTQQ/HKK6/kzTtq1KhYsWJFXHDBBVWWs3z58rx1Pnny5PjLX/4SM2fOjAsuuCAGDBgQxxxzTEH3Xm3SpEmVz69evXoxdOjQuOeee/Iuu/buu+/GzTffHNtvv300b968sDddQdu2bWOHHXaIGTNmVPsZvv/++3l1RayZbWvTTTeNPn36xJw5c2LOnDnRvn37GDRoUO7xevXqxb777ht33HFHvPzyyyuta02ouB1UfH8vv/xyPPjgg3khrW/Cj3/846hXr15MmDChyn6eUlrlLUxWR+XB4vL7SpUfDwutacstt4w2bdrENddcE8uWLcvNc91111XZVnbfffdYuHBh3H777blpX3zxRY2XP18dHTp0iN69e+cug1ju8ccfr3Ilmsrrtbi4ONepq3icA4DV9W23aSIinnrqqbxL8L/55ptxzz33xNChQ6NevXq1qqnQ7+7atAeyGDZsWHz11Vfx61//OjetrKys2pPghdhyyy2jbdu2cc011+R99z/wwAPxj3/8I/bYY4+IWL22YlFRUcycOTNGjhwZo0ePjnvvvTf3WPkAbsV+54oVK2psEy1fvjxmzJiR+3vZsmUxY8aMaNOmTd59dF999dX4z3/+U8u18LXyX7I9++yzVR4rLi6OkSNHxv/8z//E7NmzY/ny5Xm3H4n4elt55513Ys6cOXl1T5kyJZo2bRqDBw+OiK+vDJJSigkTJlR5nfI2Z/kvUipfUrSmwbyFCxfGXXfdlfv7008/jRtuuCH69u270qsmrk5bcMWKFbH//vvHsmXL4o477qj29p5Z2/ZfffVVjBkzJjp06BBXXXVVXHfddfHuu+/GSSedtNLnRXzdZ33qqadyV8+o6JNPPonly5evchm1Uci6L7Sm3XffPZYvXx5XX3117vEVK1ZUuf9tbfrwWZT/imn69Ol50wu9H++30fdZleeeey4iIgYMGPCtvSbA9011Y/JTpkwp+NfwTZo0qfZqz6NGjYq33norr11bbsmSJbF48eLVK7gahbbTdt9991ixYkVMnTo17/lXXHFFFBUVVXtCd7PNNov7778//vGPf8Tw4cNjyZIluce6desWTz/9dF7/4L777os333yz2jpvuOGG+Oyzz3J/33777fH222/nve4HH3wQr776apVbAVRW6PottN05dOjQaNasWVxyySXx5Zdf5j32Xbh61s477xwNGjSIKVOm5NVz5ZVXVpm3Nu3FI444IsrKyuK3v/1tzJw5M+rXrx+HHXbYKt9zodvct62Qtmt1fbXFixdXe4W86s7jZFXdNhlR9bNcsWJFlWNL27Zto0OHDisd165Xr17svPPOcffdd8fChQtz01977bV44IEHalVnUVFR3rHwjTfeiLvvvrva+Vc1TlFRXZy3qOk9li+z3Mr6pYWqzbF26623jgYNGsTEiRNjnXXWiV69ekXE18GMp59+Oh5//PHMV7+oTqFjJd+mrN/HhSp03Kk251ZrMmfOnDjhhBPipz/9aY1XbFpd3/oVMJYtWxY77bRTjBo1Kv75z3/G9OnTY/vtt4+99torN8/hhx8eRx99dOy7776xyy67xAsvvBBz586tcsnGvn37Rr169WLixImxaNGiKCkpiSFDhkTbtm2/kdr33HPP3C9gBgwYEC+99FLcdNNNVdKi3bp1i5YtW8Y111wTzZo1iyZNmsTWW29d6/vEPfLIIzF9+vQ499xz40c/+lFEfJ1e22GHHeKcc86JSZMmRcTXv6jYdNNNY/To0XHddddlfp/t27eP9u3bZ15ObVxyySWxxx57xPbbbx+HHnpofPTRRzFlypTo1atX3gncwYMHx1FHHRWXXHJJPP/88zF06NBo0KBBzJs3L2677ba46qqrYuTIkfGPf/wjzjnnnBgzZkwMHz48Ir4+qPft2zd3n+GV6devXzz88MMxefLk6NChQ2y44Yax9dZbx4UXXhgPPfRQbL/99jFu3LioX79+zJgxI5YuXZr7PFbHtGnTYvvtt48+ffrEEUccEV27do133303nnrqqfjvf/8bL7zwQkSs+W1+v/32i1/84hdRWloahx12WJVLMV166aXx6KOPxtZbbx1HHHFE9OzZMz766KP461//Gg8//HB89NFHq/2eq3PZZZfFbrvtFttuu20cdthhsWTJkpgyZUq0aNEizjvvvDX6WpV169YtLrzwwjjzzDPjjTfeiBEjRkSzZs1i/vz5cdddd8WRRx4Zp5xyyhp9zfnz58dee+0Vu+66azz11FNx4403xoEHHphLfhZaU4MGDeLCCy+Mo446KoYMGRL77bdfzJ8/P2bNmlXl+HTEEUfE1KlT45BDDonnnnsu2rdvH7Nnz65yP62sLr744th7771ju+22i7Fjx8bHH38cU6dOjd69e+ft04cffnh89NFHMWTIkOjUqVMsWLAgpkyZEn379vUrMQDWmG+7TdO7d+8YNmxYnHDCCVFSUpI7eVjxhHehNRX63V2b9kAWI0aMiK222ipOPvnkeO2116JHjx5x77335uqt7S+Qygcyxo4dG4MHD44DDjgg3n333bjqqquiS5cueSe8V6etWFxcHDfeeGOMGDEiRo0aFffff38MGTIkevXqFdtss02ceeaZuStB3HLLLTWeHO/QoUNMnDgx3njjjdh4441jzpw58fzzz8fMmTNz97eN+DrkPHjw4HjsscdqtR4ivv71Ru/evePhhx+OQw89tMrj++23X0yZMiXOPffc6NOnT5W20pFHHhkzZsyIMWPGxHPPPRddunSJ22+/Pf785z/HlVdemftlz4477hgHH3xw/OpXv4p58+blLqP7xBNPxI477hjHHXdc7hd2w4cPj6OOOio+//zz+PWvfx1t27atdmBj4403jsMOOyyeeeaZWG+99eLaa6+Nd999d5UDY6vTFrzmmmvikUceiaOPPrrKL5/WW2+92GWXXTK37cvvo1z+K9LNNtssfvGLX8TPf/7zGDly5ErD4aeeemrce++9seeee8aYMWOiX79+sXjx4njppZfi9ttvjzfeeGON3o6ikHVfaE3Dhw+P7bbbLs4444x44403omfPnnHnnXdWe9Kq0D58Fv369Yt99903rrzyyvjwww9jm222iccffzz3K8lVHW++rb7Pyjz00EOxwQYbxBZbbPGtvSbA982ee+4Zs2fPjhYtWkTPnj3jqaeeiocffjjWXXfdgp7fr1+/mDNnTvzsZz+L/v37R9OmTWP48OFx8MEHx6233pprU2y33XaxYsWKePXVV+PWW2+NuXPnxpZbbrlG3kOh7bThw4fHjjvuGGeffXa88cYbsfnmm8eDDz4Y99xzT4wfPz53YrqybbbZJu65557YfffdY+TIkXH33XdHgwYN4vDDD4/bb789dt111xg1alS8/vrrceONN9a4nHXWWSe23377GDt2bLz77rtx5ZVXRvfu3eOII47IzTN16tSYMGFCPProo7HDDjvU+J4LXb+FtjubN28eV1xxRRx++OHRv3//OPDAA6NVq1bxwgsvxBdffFHntzJu06ZNnHLKKXHJJZfEnnvuGbvvvnv87W9/iwceeKBK26/QttmsWbPi97//fVx33XXRqVOniPj6ZOdBBx0UV199dYwbN67Gegrd5r5thbRdhw4dGhtssEEcdthhceqpp0a9evXi2muvjTZt2lQJu/fr1y+uvvrquPDCC6N79+7Rtm3bKlcLqK3mzZvHoEGDYtKkSfHVV19Fx44d48EHH4z58+fnzffZZ59Fp06dYuTIkbH55ptH06ZN4+GHH45nnnkm7woB1TnvvPPiwQcfjO222y6OOeaYXBigd+/e8fzzzxdU5x577BGTJ0+OXXfdNQ488MB47733Ytq0adG9e/d48cUXq8xfyDhFubo4b1Gd2vZLC1WbY23jxo2jX79+8fTTT8fw4cNzfZBBgwbF4sWLY/Hixd9IAKM2YyXflqzfx4WqzbhToedWq/O///u/ccghh8S6664bO+20U9x00015jw8YMCDbeFqqhVmzZqWISPPnz89N69y5c9pjjz2qzDt48OA0ePDgKs99/PHH05FHHplatWqVmjZtmn7605+mDz/8MO+5K1asSKeffnpq3bp1aty4cRo2bFh67bXXUufOndPo0aPz5v31r3+dunbtmurVq5ciIj366KM11j969OjUpEmTamvt1atXlemV39uXX36ZTj755NS+ffvUqFGjtN1226WnnnqqyntNKaV77rkn9ezZM9WvXz9FRJo1a9ZKX6vyOvv0009T586d049+9KP01Vdf5c130kknpeLi4vTUU0+llFKaP39+iogq62ZVr1HxueX1ZTF69OjUuXPnKsu+7LLLqswbEencc8/Nm3bHHXekTTfdNJWUlKSePXumO++8s8oyy82cOTP169cvNWrUKDVr1iz16dMnnXbaaWnhwoVp+fLlqX///qlTp07pk08+yXveVVddlSIizZkzZ6Xv5dVXX02DBg1KjRo1qrJu//rXv6Zhw4alpk2bpsaNG6cdd9wx/eUvf1nl+lnZ+kgppddffz0dcsghqV27dqlBgwapY8eOac8990y333573nw1bfM17Yvlj1W3fcybNy9FRIqI9OSTT1b73HfffTcde+yxaf31108NGjRI7dq1SzvttFOaOXPmKt9zddv7qtbDww8/nLbbbrvUqFGj1Lx58zR8+PD0yiuv5M1z7rnnpohI77//ft702u7j1bnjjjvS9ttvn5o0aZKaNGmSevTokY499tj0z3/+c5XLq+kziIh07LHHVqn/lVdeSSNHjkzNmjVLrVq1Sscdd1xasmTJatWUUkrTp09PG264YSopKUlbbrll+tOf/lTt8WnBggVpr732So0bN06tW7dOJ554YvrDH/5Q5RiadZ++5ZZbUo8ePVJJSUnq3bt3uvfee9O+++6bevTokZvn9ttvT0OHDk1t27ZNDRs2TBtssEE66qij0ttvv13lNQAgi0LaNI8++miKiHTbbbflPbe8L/PMM8/kTa+uTVL+vX/jjTemjTbaKJWUlKQtttii2n5Koe2sQr+7UyqsPVBdH6CmdlT5e6zo/fffTwceeGBq1qxZatGiRRozZkz685//nCIi3XLLLVWWUVH5Oq5c95w5c9IWW2yRSkpK0jrrrJN++tOfpv/+979Vnr+6bcUvvvgiDR48ODVt2jQ9/fTTKaWv298777xzKikpSeutt14666yz0kMPPVSlvvK237PPPpu23XbbVFpamjp37pymTp1apb6IqNL2qo3Jkyenpk2bpi+++KLKY2VlZWn99ddPEZEuvPDCap//7rvvprFjx6bWrVunhg0bpj59+lTb11u+fHm67LLLUo8ePVLDhg1TmzZt0m677Zaee+653Dz33ntv2myzzVJpaWnq0qVLmjhxYrr22mtrHBOYO3du2myzzVJJSUnq0aNHlf2oOoW0BStvM+Wfb3X/Kq/7QtvRFT333HOpfv366fjjj6+yzvr37586dOiQPv7445W+r88++yydeeaZqXv37qlhw4apdevWacCAAenyyy9Py5YtSynV3LauzXGoNuu+kJpSSunDDz9MBx98cGrevHlq0aJFOvjgg9Pf/va3ascNCu3DV+4r1NSfq27MafHixenYY49N66yzTmratGkaMWJE+uc//5kiIl166aU1fgbl1nTfpzafz4oVK1L79u3Tz3/+81XWCUDNPv7441z7pmnTpmnYsGHp1VdfrTLeWdOx+/PPP08HHnhgatmyZYqIvOP9smXL0sSJE1OvXr1SSUlJatWqVerXr1+aMGFCWrRoUW6+ymN7q1LdeFyh7bTPPvssnXTSSalDhw6pQYMGaaONNkqXXXZZKisry5uvupruueeeVL9+/bTffvulFStWpJRS+uUvf5k6duyYSkpK0nbbbZeeffbZKvWVf7/97ne/S2eeeWZq27ZtatSoUdpjjz3SggUL8l6j/Ht8ZedhyhW6fgttd5bPO2DAgFx/YKuttkq/+93vco/XNG5b03mGyipvVzX1Bavr16xYsSJNmDAhd/5ohx12SC+//HK1Y/Orapu9+eabqUWLFmn48OFVatxnn31SkyZN0r///e+VvpdCt7mVnVeobt7VXT+1abs+99xzaeutt871ESZPnlxtW/Gdd95Je+yxR2rWrNkq+2K1Gdv+73//m/bZZ5/UsmXL1KJFi/STn/wkLVy4MG++pUuXplNPPTVtvvnmqVmzZqlJkyZp8803T9OnT1/pOiz3xz/+MW2xxRapYcOGqVu3buk3v/lNOvnkk1NpaWmV2mo6/vz2t7/NjTv06NEjzZo1q9o+fKHjFHV93qI6tTk+VFbTOEdKhR9rU0rp1FNPTRGRJk6cmDe9e/fuKSLS66+/vsr3kVL1+1pN/YtyhYyVZD33XZPK+0Wh38e1GUOrqf7ajDsVem61svI6a/qX9bx5UUrfzvWZrrvuuhg7dmw888wzayw5Snavv/56dO/ePWbPnh0HHXRQXZcDfM/17ds32rRps8ZuYQQAfDfcfffdsc8++8STTz4Z2223XV2Xs0btsMMO8cEHH1R7u5g1bdGiRdG1a9eYNGlSHHbYYd/468Ha6Pnnn48tttgibrzxxvjpT39a1+XU6O67744DDzwwXn/99W/9KqMAUBuPPfZY7LjjjnHbbbfFyJEj67ocvqe6dOkSvXv3jvvuu6+uS/nOGjFiRPz973+PefPm1XUp8J2zto07Fa96Fr7Pyi/TsyYvgQrw1VdfVbmE92OPPRYvvPDCSi9PCAB891W8r3TE1/e+nTJlSjRv3jx360RWT4sWLeK0006Lyy67LMrKyuq6HKhzlY83EV/ff7u4uDgGDRpUBxUVbuLEiXHccccJXwAAUEXldu68efPi/vvvN3YO8f0Yd6pf1wVQd6699tq49tpro3HjxrHNNtvUdTnA98hbb70VO++8cxx00EHRoUOHePXVV+Oaa66Jdu3axdFHH13X5QEAGRx//PGxZMmS2HbbbWPp0qVx5513xl/+8pe4+OKLo1GjRnVd3lrv9NNPj9NPP72uy4DvhEmTJsVzzz0XO+64Y9SvXz8eeOCBeOCBB+LII4+M9ddfv67LW6mnnnqqrksAAOA7qmvXrjFmzJjo2rVrLFiwIK6++upo2LBhnHbaaXVdGtS578O4kwDGD9iRRx4ZG2+8cdx2223RsmXLui4H+B5p1apV9OvXL37zm9/E+++/H02aNIk99tgjLr300lh33XXrujwAIIMhQ4bEL3/5y7jvvvviyy+/jO7du8eUKVPiuOOOq+vSgO+ZAQMGxEMPPRQXXHBBfP7557HBBhvEeeedF2effXZdlwYAAKtt1113jd/97nfxzjvvRElJSWy77bZx8cUXx0YbbVTXpUGd+z6MOxWllFJdFwEAAAAAAAAAsDYrrusCAAAAAAAAAADWdgIYAAAAAAAAAAAZCWAAAAAAAAAAAGRUv64LgFXZpfgndV3CD95DZbfVdQkAAKxlfnTE5LouYa2z30kP1nUJa51T13m9rktY6xS3m1fXJQAA1Mr2D51W1yX8oC26v31dl/CDN/bI++u6hB+0n236UF2XwFrGFTAAAAAAAAAAADISwAAAAAAAAAAAyEgAAwAAAAAAAAAgIwEMAAAAAAAAAICMBDAAAAAAAAAAADISwAAAAAAAAAAAyEgAAwAAAAAAAAAgIwEMAAAAAAAAAICMBDAAAAAAAAAAADISwAAAAAAAAAAAyEgAAwAAAAAAAAAgIwEMAAAAAAAAAICMBDAAAAAAAAAAADISwAAAAAAAAAAAyEgAAwAAAAAAAAAgIwEMAAAAAAAAAICMBDAAAAAAAAAAADISwAAAAAAAAAAAyEgAAwAAAAAAAAAgIwEMAAAAAAAAAICMBDAAAAAAAAAAADISwAAAAAAAAAAAyEgAAwAAAAAAAAAgIwEMAAAAAAAAAICMBDAAAAAAAAAAADISwAAAAAAAAAAAyEgAAwAAAAAAAAAgIwEMAAAAAAAAAICMBDAAAAAAAAAAADISwAAAAAAAAAAAyEgAAwAAAAAAAAAgIwEMAAAAAAAAAICMBDAAAAAAAAAAADISwAAAAAAAAAAAyEgAAwAAAAAAAAAgIwEMAAAAAAAAAICMBDAAAAAAAAAAADISwAAAAAAAAAAAyEgAAwAAAAAAAAAgIwEMAAAAAAAAAICMBDAAAAAAAAAAADISwAAAAAAAAAAAyEgAAwAAAAAAAAAgIwEMAAAAAAAAAICMBDAAAAAAAAAAADISwAAAAAAAAAAAyEgAAwAAAAAAAAAgIwEMAAAAAAAAAICMBDAAAAAAAAAAADISwAAAAAAAAAAAyEgAAwAAAAAAAAAgIwEMAAAAAAAAAICMBDAAAAAAAAAAADISwAAAAAAAAAAAyEgAAwAAAAAAAAAgIwEMAAAAAAAAAICMBDAAAAAAAAAAADISwAAAAAAAAAAAyEgAAwAAAAAAAAAgIwEMAAAAAAAAAICMBDAAAAAAAAAAADISwAAAAAAAAAAAyEgAAwAAAAAAAAAgIwEMAAAAAAAAAICMBDAAAAAAAAAAADISwAAAAAAAAAAAyEgAAwAAAAAAAAAgIwEMAAAAAAAAAICMBDAAAAAAAAAAADISwAAAAAAAAAAAyEgAAwAAAAAAAAAgIwEMAAAAAAAAAICMBDAAAAAAAAAAADISwAAAAAAAAAAAyEgAAwAAAAAAAAAgIwEMAAAAAAAAAICM6td1AQAAAHz/FP/4g7ouYa1z8zXD6rqEtc4XRzxW1yWsdSa0q+sKAAAA4PvLFTAAAAAAAAAAADISwAAAAAAAAAAAyEgAAwAAAAAAAAAgIwEMAAAAAAAAAICMBDAAAAAAAAAAADISwAAAAAAAAAAAyEgAAwAAAAAAAAAgIwEMAAAAAAAAAICMBDAAAAAAAAAAADISwAAAAAAAAAAAyEgAAwAAAAAAAAAgIwEMAAAAAAAAAICMBDAAAAAAAAAAADISwAAAAAAAAAAAyEgAAwAAAAAAAAAgIwEMAAAAAAAAAICMBDAAAAAAAAAAADISwAAAAAAAAAAAyKh+XRcAq1Kv1yZ1XQIAAAAAAFAHNmrxfl2X8IP21t7L6rqEH7wnP+pe1yX8oP2srgtgreMKGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGdWv6wIAAAD4/unS4qO6LmGt895eX9V1CWud//dRl7ouAQAAACDHFTAAAAAAAAAAADISwAAAAAAAAAAAyEgAAwAAAAAAAAAgIwEMAAAAAAAAAICMBDAAAAAAAAAAADISwAAAAAAAAAAAyEgAAwAAAAAAAAAgIwEMAAAAAAAAAICMBDAAAAAAAAAAADISwAAAAAAAAAAAyEgAAwAAAAAAAAAgIwEMAAAAAAAAAICMBDAAAAAAAAAAADISwAAAAAAAAAAAyEgAAwAAAAAAAAAgIwEMAAAAAAAAAICMBDAAAAAAAAAAADISwAAAAAAAAAAAyEgAAwAAAAAAAAAgIwEMAAAAAAAAAICMBDAAAAAAAAAAADISwAAAAAAAAAAAyEgAAwAAAAAAAAAgIwEMAAAAAAAAAICMBDAAAAAAAAAAADISwAAAAAAAAAAAyEgAAwAAAAAAAAAgIwEMAAAAAAAAAICMBDAAAAAAAAAAADISwAAAAAAAAAAAyEgAAwAAAAAAAAAgIwEMAAAAAAAAAICMBDAAAAAAAAAAADISwAAAAAAAAAAAyEgAAwAAAAAAAAAgIwEMAAAAAAAAAICMBDAAAAAAAAAAADKqX9cFwKq8NXTdui4BAAAAAACoA0vLnMqqS3/o8fu6LuEHr/dV4+q6hB+27eq6ANY2roABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEb167oAAAAAvn8aFq+o6xLWOv95db26LmGt02CR35XU2uC6LgAAAAC+v4xUAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkVL+uC4BV+XyDsrouAQAAAAAAqAN//vtGdV3CD1rXf3Wr6xJ+8P507KS6LuEH7qS6LoC1jCtgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJBR/bouAAAAgO+fL5Y3qOsS1jrP7XNFXZew1hl01Sl1XQIAAABAjitgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGdWv6wJgVZr+R04IAADWNn97ZcO6LmGt86N/nVDXJax17jlucl2XsBY6qa4LAACole16zavrEn7QbuzyWF2X8IPX+6rT6rqEH7RXLqnrCljbOLMNAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkJIABAAAAAAAAAJCRAAYAAAAAAAAAQEYCGAAAAAAAAAAAGQlgAAAAAAAAAABkVL+uCwAAAOD7p1HrL+q6hLVOz/XeqesS1joX/nePui5hrXP7BnVdAQAAAHx/uQIGAAAAAAAAAEBGAhgAAAAAAAAAABkJYAAAAAAAAAAAZCSAAQAAAAAAAACQkQAGAAAAAAAAAEBGAhgAAAAAAAAAABkJYAAAAAAAAAAAZCSAAQAAAAAAAACQkQAGAAAAAAAAAEBGAhgAAAAAAAAAABkJYAAAAAAAAAAAZCSAAQAAAAAAAACQkQAGAAAAAAAAAEBGAhgAAAAAAAAAABkJYAAAAAAAAAAAZCSAAQAAAAAAAACQkQAGAAAAAAAAAEBGAhgAAAAAAAAAABnVr+sCYFWav7GirksAAAAAAADqQJP6S+u6hB+0De8+sq5L+MFr0DLVdQlALbgCBgAAAAAAAABARgIYAAAAAAAAAAAZCWAAAAAAAAAAAGQkgAEAAAAAAAAAkJEABgAAAAAAAABARgIYAAAAAAAAAAAZCWAAAAAAAAAAAGQkgAEAAAAAAAAAkJEABgAAAAAAAABARgIYAAAAAAAAAAAZCWAAAAAAAAAAAGQkgAEAAAAAAAAAkJEABgAAAAAAAABARgIYAAAAAAAAAAAZCWAAAAAAAAAAAGQkgAEAAAAAAAAAkJEABgAAAAAAAABARgIYAAAAAAAAAAAZCWAAAAAAAAAAAGQkgAEAAAAAAAAAkJEABgAAAAAAAABARgIYAAAAAAAAAAAZCWAAAAAAAAAAAGQkgAEAAAAAAAAAkJEABgAAAAAAAABARgIYAAAAAAAAAAAZCWAAAAAAAAAAAGQkgAEAAAAAAAAAkJEABgAAAAAAAABARgIYAAAAAAAAAAAZCWAAAAAAAAAAAGQkgAEAAAAAAAAAkJEABgAAAAAAAABARgIYAAAAAAAAAAAZCWAAAAAAAAAAAGQkgAEAAAAAAAAAkJEABgAAAAAAAABARgIYAAAAAAAAAAAZCWAAAAAAAAAAAGQkgAEAAAAAAAAAkJEABgAAAAAAAABARgIYAAAAAAAAAAAZCWAAAAAAAAAAAGQkgAEAAAAAAAAAkJEABgAAAAAAAABARgIYAAAAAAAAAAAZCWAAAAAAAAAAAGQkgAEAAAAAAAAAkJEABgAAAAAAAABARgIYAAAAAAAAAAAZCWAAAAAAAAAAAGQkgAH8/3buEEWrAIzCsMNcBUVhNiHaBOMYDCLajO5EsJtdhWU2IIjBHVgFQQUZ+xSDIP426yBv+Lj3Ps8KzgJeDgAAAAAAAACRAAMAAAAAAAAAIBJgAAAAAAAAAABEAgwAAAAAAAAAgEiAAQAAAAAAAAAQCTAAAAAAAAAAAKJlegAAAADb8/z2x+kJq/Pm3cPpCatz7eJoesL6nE4PAAAAgO3ygAEAAAAAAAAAEAkwAAAAAAAAAAAiAQYAAAAAAAAAQCTAAAAAAAAAAACIBBgAAAAAAAAAAJEAAwAAAAAAAAAgEmAAAAAAAAAAAEQCDAAAAAAAAACASIABAAAAAAAAABAJMAAAAAAAAAAAIgEGAAAAAAAAAEAkwAAAAAAAAAAAiAQYAAAAAAAAAACRAAMAAAAAAAAAIBJgAAAAAAAAAABEAgwAAAAAAAAAgEiAAQAAAAAAAAAQCTAAAAAAAAAAACIBBgAAAAAAAABAJMAAAAAAAAAAAIgEGAAAAAAAAAAAkQADAAAAAAAAACASYAAAAAAAAAAARAIMAAAAAAAAAIBIgAEAAAAAAAAAEAkwAAAAAAAAAAAiAQYAAAAAAAAAQCTAAAAAAAAAAACIBBgAAAAAAAAAAJEAAwAAAAAAAAAgEmAAAAAAAAAAAEQCDAAAAAAAAACASIABAAAAAAAAABAJMAAAAAAAAAAAIgEGAAAAAAAAAEAkwAAAAAAAAAAAiAQYAAAAAAAAAADRMj0ALnPr88X0BAAAAAAAYMDvP8fTE3btzt0f0xN27+bVX9MTgP/gAQMAAAAAAAAAIBJgAAAAAAAAAABEAgwAAAAAAAAAgEiAAQAAAAAAAAAQCTAAAAAAAAAAACIBBgAAAAAAAABAJMAAAAAAAAAAAIgEGAAAAAAAAAAAkQADAAAAAAAAACASYAAAAAAAAAAARAIMAAAAAAAAAIBIgAEAAAAAAAAAEAkwAAAAAAAAAAAiAQYAAAAAAAAAQCTAAAAAAAAAAACIBBgAAAAAAAAAAJEAAwAAAAAAAAAgEmAAAAAAAAAAAEQCDAAAAAAAAACASIABAAAAAAAAABAJMAAAAAAAAAAAIgEGAAAAAAAAAEAkwAAAAAAAAAAAiAQYAAAAAAAAAACRAAMAAAAAAAAAIBJgAAAAAAAAAABEAgwAAAAAAAAAgEiAAQAAAAAAAAAQCTAAAAAAAAAAACIBBgAAAAAAAABAJMAAAAAAAAAAAIgEGAAAAAAAAAAAkQADAAAAAAAAACASYAAAAAAAAAAARAIMAAAAAAAAAIBIgAEAAAAAAAAAEAkwAAAAAAAAAAAiAQYAAAAAAAAAQLRMDwAAAGB77t34Pj1hdY6ffpiesDpnX+5PTwAAAAD4xwMGAAAAAAAAAEAkwAAAAAAAAAAAiAQYAAAAAAAAAACRAAMAAAAAAAAAIBJgAAAAAAAAAABEAgwAAAAAAAAAgEiAAQAAAAAAAAAQCTAAAAAAAAAAACIBBgAAAAAAAABAJMAAAAAAAAAAAIgEGAAAAAAAAAAAkQADAAAAAAAAACASYAAAAAAAAAAARAIMAAAAAAAAAIBIgAEAAAAAAAAAEAkwAAAAAAAAAAAiAQYAAAAAAAAAQCTAAAAAAAAAAACIBBgAAAAAAAAAAJEAAwAAAAAAAAAgEmAAAAAAAAAAAEQCDAAAAAAAAACASIABAAAAAAAAABAJMAAAAAAAAAAAIgEGAAAAAAAAAEAkwAAAAAAAAAAAiAQYAAAAAAAAAACRAAMAAAAAAAAAIBJgAAAAAAAAAABEAgwAAAAAAAAAgEiAAQAAAAAAAAAQCTAAAAAAAAAAACIBBgAAAAAAAABAJMAAAAAAAAAAAIgEGAAAAAAAAAAAkQADAAAAAAAAACASYAAAAAAAAAAARAIMAAAAAAAAAIBIgAEAAAAAAAAAEAkwAAAAAAAAAAAiAQYAAAAAAAAAQCTAAAAAAAAAAACIBBgAAAAAAAAAAJEAAwAAAAAAAAAgEmAAAAAAAAAAAEQCDAAAAAAAAACASIABAAAAAAAAABAJMAAAAAAAAAAAIgEGAAAAAAAAAEAkwAAAAAAAAAAAiAQYAAAAAAAAAACRAAMAAAAAAAAAIBJgAAAAAAAAAABEAgwAAAAAAAAAgEiAAQAAAAAAAAAQCTAAAAAAAAAAACIBBgAAAAAAAABAtEwPgMu8fX82PYErr6YHAAAAAACwQ+c/T6Yn7Nuj8+kFu/fp5en0hH17MD2AtfGAAQAAAAAAAAAQCTAAAAAAAAAAACIBBgAAAAAAAABAJMAAAAAAAAAAAIgEGAAAAAAAAAAAkQADAAAAAAAAACASYAAAAAAAAAAARAIMAAAAAAAAAIBIgAEAAAAAAAAAEAkwAAAAAAAAAAAiAQYAAAAAAAAAQCTAAAAAAAAAAACIBBgAAAAAAAAAAJEAAwAAAAAAAAAgEmAAAAAAAAAAAEQCDAAAAAAAAACASIABAAAAAAAAABAJMAAAAAAAAAAAomV6AAAAANvz+uvj6Qmrc/3Jt+kJ6/PiZHrB+jybHgAAAADb5QEDAAAAAAAAACASYAAAAAAAAAAARAIMAAAAAAAAAIBIgAEAAAAAAAAAEAkwAAAAAAAAAAAiAQYAAAAAAAAAQCTAAAAAAAAAAACIBBgAAAAAAAAAAJEAAwAAAAAAAAAgEmAAAAAAAAAAAEQCDAAAAAAAAACASIABAAAAAAAAABAJMAAAAAAAAAAAIgEGAAAAAAAAAEAkwAAAAAAAAAAAiAQYAAAAAAAAAACRAAMAAAAAAAAAIBJgAAAAAAAAAABEAgwAAAAAAAAAgEiAAQAAAAAAAAAQCTAAAAAAAAAAACIBBgAAAAAAAABAJMAAAAAAAAAAAIgEGAAAAAAAAAAAkQADAAAAAAAAACASYAAAAAAAAAAARAIMAAAAAAAAAIBIgAEAAAAAAAAAEAkwAAAAAAAAAAAiAQYAAAAAAAAAQCTAAAAAAAAAAACIBBgAAAAAAAAAAJEAAwAAAAAAAAAgEmAAAAAAAAAAAEQCDAAAAAAAAACASIABAAAAAAAAABAJMAAAAAAAAAAAIgEGAAAAAAAAAEAkwAAAAAAAAAAAiAQYAAAAAAAAAACRAAMAAAAAAAAAIBJgAAAAAAAAAABEAgwAAAAAAAAAgEiAAQAAAAAAAAAQCTAAAAAAAAAAACIBBgAAAAAAAABAJMAAAAAAAAAAAIgEGAAAAAAAAAAAkQADAAAAAAAAACASYAAAAAAAAAAARAIMAAAAAAAAAIBIgAEAAAAAAAAAEAkwAAAAAAAAAAAiAQYAAAAAAAAAQCTAAAAAAAAAAACIBBgAAAAAAAAAAJEAAwAAAAAAAAAgEmAAAAAAAAAAAEQCDAAAAAAAAACASIABAAAAAAAAABAJMAAAAAAAAAAAIgEGAAAAAAAAAEAkwAAAAAAAAAAAiAQYAAAAAAAAAACRAAMAAAAAAAAAIBJgAAAAAAAAAABEAgwAAAAAAAAAgEiAAQAAAAAAAAAQCTAAAAAAAAAAACIBBgAAAAAAAABAJMAAAAAAAAAAAIgEGAAAAAAAAAAAkQADAAAAAAAAACASYAAAAAAAAAAARAIMAAAAAAAAAIBIgAEAAAAAAAAAEB0dDofD9AgAAAAAAAAAgDXzgAEAAAAAAAAAEAkwAAAAAAAAAAAiAQYAAAAAAAAAQCTAAAAAAAAAAACIBBgAAAAAAAAAAJEAAwAAAAAAAAAgEmAAAAAAAAAAAEQCDAAAAAAAAACASIABAAAAAAAAABD9Bc6eubrLz1pMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 3000x1000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1,3,figsize=(30,10))\n",
    "axs[0].imshow(inp.detach().numpy().reshape(8,1))\n",
    "axs[0].set_title('input matrix. ij=index to retrive from embeddings')\n",
    "axs[1].imshow(w)\n",
    "axs[1].set_title('embedding lookup.  (vocab size x embedding dim)')\n",
    "axs[2].imshow(embedded.reshape(8,3))\n",
    "axs[2].set_title('after lookup. each index of input has grabbed a row from iamge 2 ')\n",
    "for ax in axs:\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aee997f-84fd-4097-8b71-f629924e8f29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
